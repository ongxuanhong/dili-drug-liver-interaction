{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongong/anaconda3/envs/dili-drug-liver-interaction/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "\n",
    "from transformers import AutoConfig , AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModernBERT example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"unikei/bert-base-smiles\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted token: ##1\n"
     ]
    }
   ],
   "source": [
    "text = \"The capital of France is [MASK].\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "# To get predictions for the mask:\n",
    "masked_index = inputs[\"input_ids\"][0].tolist().index(tokenizer.mask_token_id)\n",
    "predicted_token_id = outputs.logits[0, masked_index].argmax(axis=-1)\n",
    "predicted_token = tokenizer.decode(predicted_token_id)\n",
    "print(\"Predicted token:\", predicted_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1241, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Liver</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S=C=Nc1c2c(ccc1)cccc2</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1(c(cc(cc1[N+](=O)[O-])[N+](=O)[O-])[N+](=O)[...</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(c(cc(cc1)[N+](=O)[O-])[N+](=O)[O-])O</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O(CCO)CC</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oc1cc2c(cc1)cccc2</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles           Liver  label\n",
       "0                              S=C=Nc1c2c(ccc1)cccc2  Hepatotoxicity      1\n",
       "1  c1(c(cc(cc1[N+](=O)[O-])[N+](=O)[O-])[N+](=O)[...  Hepatotoxicity      1\n",
       "2            c1(c(cc(cc1)[N+](=O)[O-])[N+](=O)[O-])O  Hepatotoxicity      1\n",
       "3                                           O(CCO)CC  Hepatotoxicity      1\n",
       "4                                  Oc1cc2c(cc1)cccc2  Hepatotoxicity      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pd_train\n",
    "pd_train = pd.read_csv(\"data_smiles/Training_Group.csv\")\n",
    "pd_train[\"label\"] = pd_train[\"Liver\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0)\n",
    "print(pd_train.shape)\n",
    "pd_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1241.000000\n",
       "mean       63.667204\n",
       "std        61.782302\n",
       "min         8.000000\n",
       "25%        36.000000\n",
       "50%        48.000000\n",
       "75%        68.000000\n",
       "max       748.000000\n",
       "Name: smiles_length, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMILES length column\n",
    "pd_train[\"smiles_length\"] = pd_train[\"Smiles\"].apply(lambda x: len(x))\n",
    "pd_train[\"smiles_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Liver</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C[C@@H](C(=O)N[C@@H](C)C(=O)NC1[C@H]2[C@@H]1CN...</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C=CCOC1=C(C=C(C=C1)CC(=O)O)Cl</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCCN(CCC)C(=O)CC1=C(N=C2N1C=C(C=C2)Cl)C3=CC=C(...</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1CC2=CC=CC=C2C(C3=CC=CC=C31)NCCCCCCC(=O)O</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C1=CC=C(C=C1)CN2C3=CC=CC=C3C(=N2)OCC(=O)O</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Smiles           Liver  label\n",
       "0  C[C@@H](C(=O)N[C@@H](C)C(=O)NC1[C@H]2[C@@H]1CN...  Hepatotoxicity      1\n",
       "1                      C=CCOC1=C(C=C(C=C1)CC(=O)O)Cl  Hepatotoxicity      1\n",
       "2  CCCN(CCC)C(=O)CC1=C(N=C2N1C=C(C=C2)Cl)C3=CC=C(...  Hepatotoxicity      1\n",
       "3         C1CC2=CC=CC=C2C(C3=CC=CC=C31)NCCCCCCC(=O)O  Hepatotoxicity      1\n",
       "4          C1=CC=C(C=C1)CN2C3=CC=CC=C3C(=N2)OCC(=O)O  Hepatotoxicity      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pd_test\n",
    "pd_test = pd.read_csv(\"data_smiles/Testing_Group.csv\")\n",
    "pd_test[\"label\"] = pd_test[\"Liver\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0)\n",
    "print(pd_test.shape)\n",
    "pd_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    286.000000\n",
       "mean      54.370629\n",
       "std       39.480251\n",
       "min       10.000000\n",
       "25%       32.000000\n",
       "50%       44.000000\n",
       "75%       60.000000\n",
       "max      284.000000\n",
       "Name: smiles_length, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMILES length column\n",
    "pd_test[\"smiles_length\"] = pd_test[\"Smiles\"].apply(lambda x: len(x))\n",
    "pd_test[\"smiles_length\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train_hf = Dataset.from_pandas(pd_train)\n",
    "pd_test_hf = Dataset.from_pandas(pd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:00<00:00, 8575.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Smiles', 'Liver', 'label', 'smiles_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 1241\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max=748, min=8, avg=54/63\n",
    "max_seq_length = 748\n",
    "max_seq_length = min(max_seq_length, tokenizer.model_max_length)\n",
    "print(max_seq_length)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "  # Tokenize the texts\n",
    "  result = tokenizer(\n",
    "      examples[\"Smiles\"],\n",
    "      padding=\"max_length\",\n",
    "      max_length=max_seq_length,\n",
    "      truncation=True\n",
    "  )\n",
    "  result[\"label\"] = examples[\"label\"]\n",
    "  return result\n",
    "\n",
    "pd_train_hf_processed = pd_train_hf.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "pd_train_hf_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286/286 [00:00<00:00, 8654.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Smiles', 'Liver', 'label', 'smiles_length', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 286\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_test_hf_processed = pd_test_hf.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "pd_test_hf_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd_train_hf_processed[\"input_ids\"]\n",
    "y_train = pd_train_hf_processed[\"label\"]\n",
    "X_test = pd_test_hf_processed[\"input_ids\"]\n",
    "y_test = pd_test_hf_processed[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save data to .npy files\n",
    "np.save(\"modern_bert_data/X_train.npy\", X_train)\n",
    "np.save(\"modern_bert_data/X_test.npy\", X_test)\n",
    "np.save(\"modern_bert_data/y_train.npy\", y_train)\n",
    "np.save(\"modern_bert_data/y_test.npy\", y_test)\n",
    "\n",
    "print(\"Data saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1241, 512)\n",
      "X_test shape: (286, 512)\n",
      "y_train shape: (1241,)\n",
      "y_test shape: (286,)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_train = np.load(\"modern_bert_data/X_train.npy\")\n",
    "X_test = np.load(\"modern_bert_data/X_test.npy\")\n",
    "y_train = np.load(\"modern_bert_data/y_train.npy\")\n",
    "y_test = np.load(\"modern_bert_data/y_test.npy\")\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Find optimal threshold based on sensitivity >= 0.7 or best F1 score.\n",
    "    \"\"\"\n",
    "    best_threshold = 0.5\n",
    "    best_metrics = {\n",
    "        \"accuracy\": 0,\n",
    "        \"precision\": 0,\n",
    "        \"recall\": 0,\n",
    "        \"sensitivity\": 0,\n",
    "        \"specificity\": 0,\n",
    "        \"f1\": 0,\n",
    "    }\n",
    "\n",
    "    for threshold in np.arange(0.0, 1.0, 0.01):\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        auc = roc_auc_score(y_true, y_pred_proba)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        if sensitivity >= 0.7 or f1 > best_metrics[\"f1\"]:\n",
    "            best_threshold = threshold\n",
    "            best_metrics = {\n",
    "                \"auc\": auc,\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"f1\": f1,\n",
    "            }\n",
    "\n",
    "    return best_threshold, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "# tokenization\n",
    "model_name = \"unikei/bert-base-smiles\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# max=748, min=8, avg=54/63\n",
    "max_seq_length = 748\n",
    "max_seq_length = min(max_seq_length, tokenizer.model_max_length)\n",
    "print(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:   0%|          | 0/1241 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1241/1241 [00:00<00:00, 8824.77 examples/s]\n",
      "Running tokenizer on dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 286/286 [00:00<00:00, 8756.89 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "  # Tokenize the texts\n",
    "  result = tokenizer(\n",
    "      examples[\"Smiles\"],\n",
    "      padding=\"max_length\",\n",
    "      max_length=max_seq_length,\n",
    "      truncation=True\n",
    "  )\n",
    "  result[\"label\"] = examples[\"label\"]\n",
    "  return result\n",
    "\n",
    "# \n",
    "pd_train_hf = Dataset.from_pandas(pd_train)\n",
    "pd_test_hf = Dataset.from_pandas(pd_test)\n",
    "\n",
    "pd_train_hf_processed = pd_train_hf.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "pd_test_hf_processed = pd_test_hf.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertConfig {\n",
       "  \"_name_or_path\": \"unikei/bert-base-smiles\",\n",
       "  \"architectures\": [\n",
       "    \"BertForPreTraining\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"finetuning_task\": \"text-classification\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"torch_dtype\": \"float32\",\n",
       "  \"transformers_version\": \"4.47.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30000\n",
       "}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_labels = 2\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels,\n",
    "    finetuning_task=\"text-classification\"\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at unikei/bert-base-smiles and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, config=config)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  predictions = np.argmax(predictions , axis=1)\n",
    "  result = metric.compute(predictions=predictions, references=labels)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9950/2186343888.py:13: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"save_model\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=[\"tensorboard\"],  # Only use tensorboard\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=pd_train_hf_processed,\n",
    "    eval_dataset=pd_test_hf_processed,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1248' max='1248' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1248/1248 15:03, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.821928</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.674736</td>\n",
       "      <td>0.548951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.576907</td>\n",
       "      <td>0.699301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>0.811309</td>\n",
       "      <td>0.555944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>1.058315</td>\n",
       "      <td>0.590909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.587400</td>\n",
       "      <td>1.068299</td>\n",
       "      <td>0.643357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>1.645828</td>\n",
       "      <td>0.531469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>1.606146</td>\n",
       "      <td>0.573427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 58s, sys: 6.41 s, total: 15min 4s\n",
      "Wall time: 15min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1248, training_loss=0.3555318193557935, metrics={'train_runtime': 904.4731, 'train_samples_per_second': 10.977, 'train_steps_per_second': 1.38, 'total_flos': 2612166557614080.0, 'train_loss': 0.3555318193557935, 'epoch': 8.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and load trainer\n",
    "trainer.save_model(\"save_model_bert_base_smiles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.5769072771072388,\n",
       " 'test_accuracy': 0.6993006993006993,\n",
       " 'test_runtime': 8.1883,\n",
       " 'test_samples_per_second': 34.928,\n",
       " 'test_steps_per_second': 4.396}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = trainer.predict(pd_test_hf_processed) \n",
    "outputs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_threshold(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Find optimal threshold based on sensitivity >= 0.7 or best F1 score.\n",
    "    \"\"\"\n",
    "    best_threshold = 0.5\n",
    "    best_metrics = {\n",
    "        \"accuracy\": 0,\n",
    "        \"precision\": 0,\n",
    "        \"recall\": 0,\n",
    "        \"sensitivity\": 0,\n",
    "        \"specificity\": 0,\n",
    "        \"f1\": 0,\n",
    "    }\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "    for threshold in np.arange(0.0, 1.0, 0.01):\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "        # Calculate metrics\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "        if sensitivity >= 0.7 or f1 > best_metrics[\"f1\"]:\n",
    "            best_threshold = threshold\n",
    "            best_metrics = {\n",
    "                \"accuracy\": accuracy,\n",
    "                \"precision\": precision,\n",
    "                \"recall\": recall,\n",
    "                \"sensitivity\": sensitivity,\n",
    "                \"specificity\": specificity,\n",
    "                \"f1\": f1,\n",
    "            }\n",
    "\n",
    "    return best_threshold, best_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Metrics:\n",
      "--------------------------------------------------\n",
      "Accuracy        : 0.6608\n",
      "Auc             : 0.6721\n",
      "Precision       : 0.8333\n",
      "Recall          : 0.7014\n",
      "F1              : 0.7617\n",
      "Sensitivity     : 0.7014\n",
      "Specificity     : 0.5231\n",
      "\n",
      "Confusion Matrix:\n",
      "--------------------------------------------------\n",
      "true_negatives  : 34\n",
      "false_positives : 31\n",
      "false_negatives : 66\n",
      "true_positives  : 155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hongong/anaconda3/envs/dili-drug-liver-interaction/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, \n",
    "    precision_score, \n",
    "    recall_score, \n",
    "    f1_score, \n",
    "    confusion_matrix,\n",
    "    accuracy_score\n",
    ")\n",
    "\n",
    "def compute_binary_metrics(pred_probs, pred_labels, true_labels):\n",
    "    \"\"\"\n",
    "    Compute comprehensive binary classification metrics\n",
    "    \"\"\"\n",
    "    # labels, pred_labels to numpy\n",
    "    true_labels = np.array(true_labels)\n",
    "    pred_labels = np.array(pred_labels)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, pred_labels).ravel()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(true_labels, pred_labels),\n",
    "        \"auc\": roc_auc_score(true_labels, pred_probs),\n",
    "        \"precision\": precision_score(true_labels, pred_labels),\n",
    "        \"recall\": recall_score(true_labels, pred_labels),\n",
    "        \"f1\": f1_score(true_labels, pred_labels),\n",
    "        \"sensitivity\": tp / (tp + fn),  # Same as recall\n",
    "        \"specificity\": tn / (tn + fp),\n",
    "        \"confusion_matrix\": {\n",
    "            \"true_negatives\": tn,\n",
    "            \"false_positives\": fp,\n",
    "            \"false_negatives\": fn,\n",
    "            \"true_positives\": tp\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Process trainer.predict outputs\n",
    "outputs = trainer.predict(pd_test_hf_processed)\n",
    "logits = outputs.predictions\n",
    "true_labels = outputs.label_ids\n",
    "\n",
    "# Get probabilities and predicted labels\n",
    "logits = torch.tensor(logits)\n",
    "probs = logits.softmax(axis=1)\n",
    "pred_probs = probs[:, 1]  # For binary classification, take probability of positive class\n",
    "# pred_labels = np.argmax(logits, axis=1)\n",
    "\n",
    "# Find optimal threshold\n",
    "best_threshold, best_metrics = find_optimal_threshold(true_labels, pred_probs)\n",
    "pred_probs = np.array(pred_probs)\n",
    "pred_labels = (pred_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Compute all metrics\n",
    "all_metrics = compute_binary_metrics(pred_probs, pred_labels, true_labels)\n",
    "\n",
    "# Print results in a formatted way\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(\"-\" * 50)\n",
    "for metric, value in all_metrics.items():\n",
    "    if metric != \"confusion_matrix\":\n",
    "        print(f\"{metric.capitalize():15} : {value:.4f}\")\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"-\" * 50)\n",
    "for key, value in all_metrics[\"confusion_matrix\"].items():\n",
    "    print(f\"{key:15} : {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili-drug-liver-interaction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
