{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/home/m12gbs1/miniconda3/envs/dili/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_add_pool\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import deepchem as dc\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    log_loss,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing SMILES Data into Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurization using DeepChem's MolGraphConvFeaturizer\n",
    "from utils.SmilesEnumeration import SmilesEnumerator\n",
    "\n",
    "\n",
    "def featurize_smiles(smiles):\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "    graph_data = featurizer.featurize([smiles])[0]\n",
    "\n",
    "    # Get DeepChem atom features\n",
    "    atom_features_deepchem = graph_data.node_features\n",
    "\n",
    "    return atom_features_deepchem\n",
    "\n",
    "\n",
    "# Function to generate Morgan Fingerprints (ECFP)\n",
    "def generate_ecfp(smiles):\n",
    "    # Morgan fingerprint generator\n",
    "    mfgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096)\n",
    "\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "    return mfgen.GetFingerprintAsNumPy(molecule)\n",
    "\n",
    "\n",
    "# Function to convert SMILES to PyTorch Geometric Data object using DeepChem featurizer\n",
    "def smiles_to_graph_featurizer(smiles):\n",
    "    # Featurization using DeepChem\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "\n",
    "    # Featurize the SMILES string using DeepChem\n",
    "    graph_data = featurizer.featurize([smiles])[0]\n",
    "    return graph_data.node_features, graph_data.edge_features, graph_data.edge_index\n",
    "\n",
    "\n",
    "# Function to extract atom features\n",
    "def atom_features(atom, ecfp):\n",
    "    # Get the atom index for corresponding ECFP value\n",
    "    atom_idx = atom.GetIdx()\n",
    "\n",
    "    return [\n",
    "        atom.GetAtomicNum(),  # Atomic number\n",
    "        atom.GetDegree(),  # Number of bonds\n",
    "        atom.GetTotalNumHs(),  # Total number of hydrogens\n",
    "        atom.GetFormalCharge(),  # Formal charge of the atom\n",
    "        atom.GetImplicitValence(),  # Implicit valence\n",
    "        atom.GetNumRadicalElectrons(),  # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),  # Is the atom aromatic?\n",
    "        atom.GetMass(),  # Atomic mass\n",
    "        atom.GetHybridization().real,  # Hybridization state (SP, SP2, SP3, etc.)\n",
    "        ecfp[atom_idx],  # Morgan fingerprint (ECFP) for the atom\n",
    "    ]\n",
    "\n",
    "\n",
    "# Function to extract bond features\n",
    "def bond_features(bond):\n",
    "    bond_type = bond.GetBondTypeAsDouble()  # Bond type as a float\n",
    "    is_aromatic = bond.GetIsAromatic()  # Aromatic bond\n",
    "    is_conjugated = bond.GetIsConjugated()  # Conjugated bond\n",
    "    is_in_ring = bond.IsInRing()  # Whether the bond is part of a ring\n",
    "    stereo = bond.GetStereo()  # Bond stereochemistry\n",
    "\n",
    "    # Convert stereo information to a one-hot encoded format\n",
    "    stereo_one_hot = [0, 0, 0, 0]  # Stereo options: None, E, Z, Other\n",
    "    if stereo == Chem.BondStereo.STEREONONE:\n",
    "        stereo_one_hot[0] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOE:\n",
    "        stereo_one_hot[1] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOZ:\n",
    "        stereo_one_hot[2] = 1\n",
    "    else:\n",
    "        stereo_one_hot[3] = 1\n",
    "\n",
    "    # Combine all features into a single tensor\n",
    "    return [\n",
    "        bond_type,\n",
    "        float(is_aromatic),\n",
    "        float(is_conjugated),\n",
    "        float(is_in_ring),\n",
    "    ] + stereo_one_hot\n",
    "\n",
    "\n",
    "# Convert SMILES to PyTorch Geometric Data object\n",
    "def smiles_to_graph(smiles, label):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    atom_features_list = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    # DeepChem features\n",
    "    atom_features_deepchem = featurize_smiles(smiles)\n",
    "\n",
    "    # Generate Morgan Fingerprint (ECFP)\n",
    "    ecfp_features = generate_ecfp(smiles)\n",
    "\n",
    "    # Generate Molecule Graph Convolution features\n",
    "    mol_graph_node_features, mol_graph_edge_features, mol_graph_edge_index = (\n",
    "        smiles_to_graph_featurizer(smiles)\n",
    "    )\n",
    "\n",
    "    # Nodes (atoms)\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_features(atom, ecfp_features))\n",
    "\n",
    "    atom_features_list = np.array(atom_features_list)\n",
    "\n",
    "    # Edges (bonds)\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        # Append bidirectional edges for undirected graphs\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "\n",
    "        # Append bond features for both directions\n",
    "        edge_attr.append(bond_features(bond))\n",
    "        edge_attr.append(bond_features(bond))\n",
    "\n",
    "    # Convert atom features to a tensor\n",
    "    combined_features = np.concatenate(\n",
    "        (atom_features_list, atom_features_deepchem, mol_graph_node_features), axis=1\n",
    "    )\n",
    "    x = torch.tensor(combined_features, dtype=torch.float)\n",
    "\n",
    "    # Convert edge indices and features to tensors, handle empty edge case\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # combine edge features from ECFP and MolGraphConv\n",
    "    edge_attr = np.array(edge_attr)\n",
    "    edge_attr = np.concatenate((edge_attr, mol_graph_edge_features), axis=1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Label (target)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "\n",
    "# Function to load data from parquet and apply SMILES augmentation for training\n",
    "def load_data_from_parquet(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    smiles_list = df[\"Smiles\"].values\n",
    "    labels = df[\"Liver\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0).values\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    # Initialize the SmilesEnumerator for data augmentation\n",
    "    for smiles, label in zip(smiles_list, labels):\n",
    "        # For test data, no augmentation, just use canonical SMILES\n",
    "        graph_data = smiles_to_graph(smiles, label)\n",
    "        data_list.append(graph_data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "data1 = load_data_from_parquet(\"data/training_class_mixed.parquet\")\n",
    "data2 = load_data_from_parquet(\"data/testing_class_mixed.parquet\")\n",
    "dataset = data1 + data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_features,\n",
    "        num_classes,\n",
    "        num_layers=3,\n",
    "        hidden_dim=64,\n",
    "        dropout_prob=0.5,\n",
    "        activation=\"relu\",\n",
    "    ):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Store activation function dynamically\n",
    "        if activation == \"relu\":\n",
    "            self.activation = F.relu\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = F.tanh\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Dynamically define the GCN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(num_node_features, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Final fully connected layer\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Apply GCN layers dynamically\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation(x)\n",
    "\n",
    "        # Global pooling (combine different pooling methods)\n",
    "        x = torch.cat([global_mean_pool(x, batch), global_add_pool(x, batch)], dim=1)\n",
    "\n",
    "        # Apply dropout\n",
    "        x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
    "\n",
    "        # Final classification layer\n",
    "        return F.log_softmax(self.fc(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter Suggestions\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout_prob = trial.suggest_float(\"dropout_prob\", 0.1, 0.7)\n",
    "\n",
    "    # Get number of features and classes\n",
    "    num_node_features = 70\n",
    "    num_classes = 2\n",
    "\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y = [data.y.item() for data in dataset]\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(np.zeros(len(dataset)), y):\n",
    "        train_dataset = [dataset[i] for i in train_idx]\n",
    "        test_dataset = [dataset[i] for i in test_idx]\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize Model\n",
    "        model = GCN(\n",
    "            num_node_features=num_node_features,\n",
    "            num_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_prob=dropout_prob,\n",
    "            activation=activation,\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for epoch in range(50):  # Fixed number of epochs\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = criterion(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(batch)\n",
    "            y_true.append(batch.y.cpu().numpy())\n",
    "            y_pred.append(out[:, 1].cpu().numpy())  # Assuming binary classification\n",
    "\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Return Mean AUC\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-16 21:44:11,781] A new study created in memory with name: no-name-d8e3ff5e-59fa-4785-9588-92a2cba346c7\n",
      "[I 2024-11-16 21:44:33,031] Trial 0 finished with value: 0.6840311586368047 and parameters: {'hidden_dim': 87, 'num_layers': 3, 'learning_rate': 0.0002101334379110023, 'weight_decay': 7.749211556818577e-05, 'activation': 'relu', 'dropout_prob': 0.3526595564240842}. Best is trial 0 with value: 0.6840311586368047.\n",
      "[I 2024-11-16 21:44:54,012] Trial 1 finished with value: 0.6878957310045744 and parameters: {'hidden_dim': 100, 'num_layers': 3, 'learning_rate': 0.0007013223283524469, 'weight_decay': 1.1632312498514195e-05, 'activation': 'relu', 'dropout_prob': 0.13387898063139347}. Best is trial 1 with value: 0.6878957310045744.\n",
      "[I 2024-11-16 21:45:12,547] Trial 2 finished with value: 0.6759532537277966 and parameters: {'hidden_dim': 30, 'num_layers': 2, 'learning_rate': 0.0002993167666934607, 'weight_decay': 0.0006949757348561444, 'activation': 'tanh', 'dropout_prob': 0.34883755270548567}. Best is trial 1 with value: 0.6878957310045744.\n",
      "[I 2024-11-16 21:45:35,985] Trial 3 finished with value: 0.6135513661656666 and parameters: {'hidden_dim': 105, 'num_layers': 4, 'learning_rate': 0.00392580339623319, 'weight_decay': 5.9005644392071483e-05, 'activation': 'tanh', 'dropout_prob': 0.4360008049479682}. Best is trial 1 with value: 0.6878957310045744.\n",
      "[I 2024-11-16 21:45:54,185] Trial 4 finished with value: 0.6725452195092971 and parameters: {'hidden_dim': 100, 'num_layers': 2, 'learning_rate': 0.003154367575014293, 'weight_decay': 0.00010188639428371765, 'activation': 'tanh', 'dropout_prob': 0.1332293044436028}. Best is trial 1 with value: 0.6878957310045744.\n",
      "[I 2024-11-16 21:46:15,026] Trial 5 finished with value: 0.6891301697063309 and parameters: {'hidden_dim': 49, 'num_layers': 3, 'learning_rate': 0.0011758891880549358, 'weight_decay': 6.504437154898951e-05, 'activation': 'relu', 'dropout_prob': 0.43359170127533386}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:46:35,847] Trial 6 finished with value: 0.6702567599358402 and parameters: {'hidden_dim': 26, 'num_layers': 3, 'learning_rate': 0.004049298899691397, 'weight_decay': 1.748081430165818e-05, 'activation': 'relu', 'dropout_prob': 0.4889102775787375}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:46:54,429] Trial 7 finished with value: 0.685330530901602 and parameters: {'hidden_dim': 89, 'num_layers': 2, 'learning_rate': 0.0012559847705923299, 'weight_decay': 1.78112151289368e-05, 'activation': 'tanh', 'dropout_prob': 0.633672008282924}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:47:17,945] Trial 8 finished with value: 0.6732927519356819 and parameters: {'hidden_dim': 96, 'num_layers': 4, 'learning_rate': 0.0012874798317984303, 'weight_decay': 7.168114146238168e-05, 'activation': 'tanh', 'dropout_prob': 0.5949325291386519}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:47:41,595] Trial 9 finished with value: 0.6817598708885324 and parameters: {'hidden_dim': 81, 'num_layers': 4, 'learning_rate': 0.00014541206022967892, 'weight_decay': 0.0002714762415827993, 'activation': 'relu', 'dropout_prob': 0.23339186370126494}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:48:02,645] Trial 10 finished with value: 0.6767127356977367 and parameters: {'hidden_dim': 55, 'num_layers': 3, 'learning_rate': 0.0004691366445953839, 'weight_decay': 0.00022784232124086937, 'activation': 'relu', 'dropout_prob': 0.5451958462178867}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:48:23,559] Trial 11 finished with value: 0.6860156201112894 and parameters: {'hidden_dim': 57, 'num_layers': 3, 'learning_rate': 0.0006157928304379053, 'weight_decay': 1.070861587249149e-05, 'activation': 'relu', 'dropout_prob': 0.23293813311742237}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:48:44,246] Trial 12 finished with value: 0.5237744715736945 and parameters: {'hidden_dim': 50, 'num_layers': 3, 'learning_rate': 0.00983249542793047, 'weight_decay': 3.449069421577724e-05, 'activation': 'relu', 'dropout_prob': 0.2635600887396542}. Best is trial 5 with value: 0.6891301697063309.\n",
      "[I 2024-11-16 21:49:05,237] Trial 13 finished with value: 0.695749884156122 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'learning_rate': 0.0007341215437831003, 'weight_decay': 3.1671165033745054e-05, 'activation': 'relu', 'dropout_prob': 0.10122151375898883}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:49:23,312] Trial 14 finished with value: 0.678250190300798 and parameters: {'hidden_dim': 68, 'num_layers': 2, 'learning_rate': 0.001796422500984866, 'weight_decay': 3.252980514080196e-05, 'activation': 'relu', 'dropout_prob': 0.4283690253940735}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:49:45,628] Trial 15 finished with value: 0.6809963611160618 and parameters: {'hidden_dim': 116, 'num_layers': 4, 'learning_rate': 0.0003327879795808735, 'weight_decay': 0.00013971096325278163, 'activation': 'relu', 'dropout_prob': 0.6835031474188372}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:50:05,635] Trial 16 finished with value: 0.6946216875581694 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'learning_rate': 0.0021610610754291323, 'weight_decay': 3.667713145005033e-05, 'activation': 'relu', 'dropout_prob': 0.3142899910545441}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:50:23,113] Trial 17 finished with value: 0.6907470112279451 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'learning_rate': 0.0021775703016330807, 'weight_decay': 3.365049133131355e-05, 'activation': 'relu', 'dropout_prob': 0.11422608370140595}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:50:43,071] Trial 18 finished with value: 0.5604854187211628 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'learning_rate': 0.007546817103586219, 'weight_decay': 2.2220672238377313e-05, 'activation': 'relu', 'dropout_prob': 0.277836018423555}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:51:05,343] Trial 19 finished with value: 0.6830674349987129 and parameters: {'hidden_dim': 115, 'num_layers': 4, 'learning_rate': 0.0008166261735196003, 'weight_decay': 4.1984990962868434e-05, 'activation': 'relu', 'dropout_prob': 0.18064421216500384}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:51:25,528] Trial 20 finished with value: 0.685563160458623 and parameters: {'hidden_dim': 114, 'num_layers': 3, 'learning_rate': 0.002308945719632435, 'weight_decay': 0.0001603807797039924, 'activation': 'relu', 'dropout_prob': 0.33920986963258165}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:51:43,114] Trial 21 finished with value: 0.689426078932256 and parameters: {'hidden_dim': 124, 'num_layers': 2, 'learning_rate': 0.0019842857633721256, 'weight_decay': 2.598905056110613e-05, 'activation': 'relu', 'dropout_prob': 0.10983671081986748}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:52:00,632] Trial 22 finished with value: 0.6851331606566468 and parameters: {'hidden_dim': 128, 'num_layers': 2, 'learning_rate': 0.0028304426643899223, 'weight_decay': 4.275875587485758e-05, 'activation': 'relu', 'dropout_prob': 0.18799791373003988}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:52:18,073] Trial 23 finished with value: 0.6404422226182697 and parameters: {'hidden_dim': 109, 'num_layers': 2, 'learning_rate': 0.005256888118056461, 'weight_decay': 4.5982271978434065e-05, 'activation': 'relu', 'dropout_prob': 0.19537882955446012}. Best is trial 13 with value: 0.695749884156122.\n",
      "[I 2024-11-16 21:52:35,562] Trial 24 finished with value: 0.699946893997901 and parameters: {'hidden_dim': 121, 'num_layers': 2, 'learning_rate': 0.0017029800536949508, 'weight_decay': 2.3711967205175787e-05, 'activation': 'relu', 'dropout_prob': 0.11084677956783127}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:52:55,281] Trial 25 finished with value: 0.6947252349551476 and parameters: {'hidden_dim': 119, 'num_layers': 3, 'learning_rate': 0.0009740485637330467, 'weight_decay': 1.572840374551347e-05, 'activation': 'relu', 'dropout_prob': 0.30310116111096347}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:53:17,837] Trial 26 finished with value: 0.6890826091605774 and parameters: {'hidden_dim': 115, 'num_layers': 4, 'learning_rate': 0.0005216331153039388, 'weight_decay': 1.4479227989410313e-05, 'activation': 'tanh', 'dropout_prob': 0.16365111043509137}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:53:37,636] Trial 27 finished with value: 0.692446755777342 and parameters: {'hidden_dim': 75, 'num_layers': 3, 'learning_rate': 0.0009253617746321346, 'weight_decay': 2.617090771938304e-05, 'activation': 'relu', 'dropout_prob': 0.23004727430417332}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:53:55,290] Trial 28 finished with value: 0.6838547884116516 and parameters: {'hidden_dim': 121, 'num_layers': 2, 'learning_rate': 0.001525885998985365, 'weight_decay': 1.5550062866557743e-05, 'activation': 'relu', 'dropout_prob': 0.38606535633333355}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:54:15,268] Trial 29 finished with value: 0.699125787837383 and parameters: {'hidden_dim': 94, 'num_layers': 3, 'learning_rate': 0.00021249991543229998, 'weight_decay': 2.213327913541366e-05, 'activation': 'relu', 'dropout_prob': 0.2904933860513744}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:54:35,005] Trial 30 finished with value: 0.6915056987267074 and parameters: {'hidden_dim': 92, 'num_layers': 3, 'learning_rate': 0.00012102625101474614, 'weight_decay': 9.247713661147981e-05, 'activation': 'relu', 'dropout_prob': 0.10307157366449303}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:54:55,339] Trial 31 finished with value: 0.6892671498445514 and parameters: {'hidden_dim': 119, 'num_layers': 3, 'learning_rate': 0.00037616221141855777, 'weight_decay': 2.2618328744134893e-05, 'activation': 'relu', 'dropout_prob': 0.2876460699213489}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:55:15,889] Trial 32 finished with value: 0.6901535658131844 and parameters: {'hidden_dim': 105, 'num_layers': 3, 'learning_rate': 0.00019903771393828894, 'weight_decay': 1.038562281650693e-05, 'activation': 'relu', 'dropout_prob': 0.1498300709138305}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:55:36,295] Trial 33 finished with value: 0.6878755024851977 and parameters: {'hidden_dim': 106, 'num_layers': 3, 'learning_rate': 0.00025463332946521725, 'weight_decay': 1.500614195243338e-05, 'activation': 'relu', 'dropout_prob': 0.3761151605915398}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:55:59,318] Trial 34 finished with value: 0.6772970086536368 and parameters: {'hidden_dim': 110, 'num_layers': 4, 'learning_rate': 0.0007931068603321072, 'weight_decay': 0.0007162777291870053, 'activation': 'relu', 'dropout_prob': 0.31171122561713566}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:56:19,489] Trial 35 finished with value: 0.6726633462048752 and parameters: {'hidden_dim': 97, 'num_layers': 3, 'learning_rate': 0.00017333046384405913, 'weight_decay': 2.0628759665245588e-05, 'activation': 'tanh', 'dropout_prob': 0.21521947646221423}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:56:36,926] Trial 36 finished with value: 0.61471008455613 and parameters: {'hidden_dim': 18, 'num_layers': 2, 'learning_rate': 0.00010711779920478511, 'weight_decay': 5.285115374273847e-05, 'activation': 'relu', 'dropout_prob': 0.49871448884256464}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:56:56,824] Trial 37 finished with value: 0.6900906489237412 and parameters: {'hidden_dim': 102, 'num_layers': 3, 'learning_rate': 0.0010258412904116181, 'weight_decay': 1.2713445493429361e-05, 'activation': 'tanh', 'dropout_prob': 0.15072318684720834}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:57:14,695] Trial 38 finished with value: 0.6888938822550942 and parameters: {'hidden_dim': 85, 'num_layers': 2, 'learning_rate': 0.0006348185119072986, 'weight_decay': 2.785301594811181e-05, 'activation': 'relu', 'dropout_prob': 0.2537792625711839}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:57:35,261] Trial 39 finished with value: 0.6766515558723935 and parameters: {'hidden_dim': 123, 'num_layers': 3, 'learning_rate': 0.00024942587676947403, 'weight_decay': 0.0004576674188032207, 'activation': 'relu', 'dropout_prob': 0.47755745804089267}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:57:55,691] Trial 40 finished with value: 0.6828701479237212 and parameters: {'hidden_dim': 110, 'num_layers': 3, 'learning_rate': 0.00041561379187106704, 'weight_decay': 1.9057940920909967e-05, 'activation': 'tanh', 'dropout_prob': 0.345637768243541}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:58:15,617] Trial 41 finished with value: 0.6745926810431889 and parameters: {'hidden_dim': 122, 'num_layers': 3, 'learning_rate': 0.0014859838125208134, 'weight_decay': 3.559030140037644e-05, 'activation': 'relu', 'dropout_prob': 0.31635072990866203}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:58:35,397] Trial 42 finished with value: 0.6879888568090458 and parameters: {'hidden_dim': 120, 'num_layers': 3, 'learning_rate': 0.00320404570677418, 'weight_decay': 2.6790018875530763e-05, 'activation': 'relu', 'dropout_prob': 0.30144503432943764}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:58:55,635] Trial 43 finished with value: 0.691372610150696 and parameters: {'hidden_dim': 94, 'num_layers': 3, 'learning_rate': 0.001185442628323385, 'weight_decay': 5.9266649710931903e-05, 'activation': 'relu', 'dropout_prob': 0.3681855025156195}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:59:15,573] Trial 44 finished with value: 0.6836812459652666 and parameters: {'hidden_dim': 102, 'num_layers': 3, 'learning_rate': 0.0044261215877432515, 'weight_decay': 1.3049564656452614e-05, 'activation': 'relu', 'dropout_prob': 0.4148579044606315}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:59:37,865] Trial 45 finished with value: 0.6920491265173567 and parameters: {'hidden_dim': 111, 'num_layers': 4, 'learning_rate': 0.0015350691475692752, 'weight_decay': 8.849274202874672e-05, 'activation': 'relu', 'dropout_prob': 0.13462545488529043}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 21:59:57,520] Trial 46 finished with value: 0.6933790063169567 and parameters: {'hidden_dim': 71, 'num_layers': 3, 'learning_rate': 0.002811589664799659, 'weight_decay': 1.771791920114917e-05, 'activation': 'relu', 'dropout_prob': 0.3271015561959335}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 22:00:17,482] Trial 47 finished with value: 0.6857831347155389 and parameters: {'hidden_dim': 128, 'num_layers': 3, 'learning_rate': 0.0010262369754277631, 'weight_decay': 4.886336784664104e-05, 'activation': 'relu', 'dropout_prob': 0.4569974589646223}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 22:00:37,497] Trial 48 finished with value: 0.6895327131230321 and parameters: {'hidden_dim': 81, 'num_layers': 3, 'learning_rate': 0.0017931146941938313, 'weight_decay': 7.166375676883551e-05, 'activation': 'tanh', 'dropout_prob': 0.2528402545465459}. Best is trial 24 with value: 0.699946893997901.\n",
      "[I 2024-11-16 22:00:57,620] Trial 49 finished with value: 0.677381202796095 and parameters: {'hidden_dim': 42, 'num_layers': 3, 'learning_rate': 0.0024799141958672384, 'weight_decay': 0.0009102086473372229, 'activation': 'relu', 'dropout_prob': 0.20252210311805785}. Best is trial 24 with value: 0.699946893997901.\n"
     ]
    }
   ],
   "source": [
    "# Optuna Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC Score: 0.699946893997901\n",
      "Best Hyperparameters: {'hidden_dim': 121, 'num_layers': 2, 'learning_rate': 0.0017029800536949508, 'weight_decay': 2.3711967205175787e-05, 'activation': 'relu', 'dropout_prob': 0.11084677956783127}\n"
     ]
    }
   ],
   "source": [
    "# Output the best parameters and score\n",
    "print(\"Best AUC Score:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
