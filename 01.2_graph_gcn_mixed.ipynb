{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_add_pool\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import deepchem as dc\n",
    "import random\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    log_loss,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "\n",
    "from pprint import pprint\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing SMILES Data into Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Featurization using DeepChem's MolGraphConvFeaturizer\n",
    "from utils.SmilesEnumeration import SmilesEnumerator\n",
    "\n",
    "\n",
    "def featurize_smiles(smiles):\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "    graph_data = featurizer.featurize([smiles])[0]\n",
    "\n",
    "    # Get DeepChem atom features\n",
    "    atom_features_deepchem = graph_data.node_features\n",
    "\n",
    "    return atom_features_deepchem\n",
    "\n",
    "\n",
    "# Function to generate Morgan Fingerprints (ECFP)\n",
    "def generate_ecfp(smiles):\n",
    "    # Morgan fingerprint generator\n",
    "    mfgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096)\n",
    "\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "    return mfgen.GetFingerprintAsNumPy(molecule)\n",
    "\n",
    "\n",
    "# Function to convert SMILES to PyTorch Geometric Data object using DeepChem featurizer\n",
    "def smiles_to_graph_featurizer(smiles):\n",
    "    # Featurization using DeepChem\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "\n",
    "    # Featurize the SMILES string using DeepChem\n",
    "    graph_data = featurizer.featurize([smiles])[0]\n",
    "    return graph_data.node_features, graph_data.edge_features, graph_data.edge_index\n",
    "\n",
    "\n",
    "# Function to extract atom features\n",
    "def atom_features(atom, ecfp):\n",
    "    # Get the atom index for corresponding ECFP value\n",
    "    atom_idx = atom.GetIdx()\n",
    "\n",
    "    return [\n",
    "        atom.GetAtomicNum(),  # Atomic number\n",
    "        atom.GetDegree(),  # Number of bonds\n",
    "        atom.GetTotalNumHs(),  # Total number of hydrogens\n",
    "        atom.GetFormalCharge(),  # Formal charge of the atom\n",
    "        atom.GetImplicitValence(),  # Implicit valence\n",
    "        atom.GetNumRadicalElectrons(),  # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),  # Is the atom aromatic?\n",
    "        atom.GetMass(),  # Atomic mass\n",
    "        atom.GetHybridization().real,  # Hybridization state (SP, SP2, SP3, etc.)\n",
    "        ecfp[atom_idx],  # Morgan fingerprint (ECFP) for the atom\n",
    "    ]\n",
    "\n",
    "\n",
    "# Function to extract bond features\n",
    "def bond_features(bond):\n",
    "    bond_type = bond.GetBondTypeAsDouble()  # Bond type as a float\n",
    "    is_aromatic = bond.GetIsAromatic()  # Aromatic bond\n",
    "    is_conjugated = bond.GetIsConjugated()  # Conjugated bond\n",
    "    is_in_ring = bond.IsInRing()  # Whether the bond is part of a ring\n",
    "    stereo = bond.GetStereo()  # Bond stereochemistry\n",
    "\n",
    "    # Convert stereo information to a one-hot encoded format\n",
    "    stereo_one_hot = [0, 0, 0, 0]  # Stereo options: None, E, Z, Other\n",
    "    if stereo == Chem.BondStereo.STEREONONE:\n",
    "        stereo_one_hot[0] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOE:\n",
    "        stereo_one_hot[1] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOZ:\n",
    "        stereo_one_hot[2] = 1\n",
    "    else:\n",
    "        stereo_one_hot[3] = 1\n",
    "\n",
    "    # Combine all features into a single tensor\n",
    "    return [\n",
    "        bond_type,\n",
    "        float(is_aromatic),\n",
    "        float(is_conjugated),\n",
    "        float(is_in_ring),\n",
    "    ] + stereo_one_hot\n",
    "\n",
    "\n",
    "# Convert SMILES to PyTorch Geometric Data object\n",
    "def smiles_to_graph(smiles, label):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    atom_features_list = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    # DeepChem features\n",
    "    atom_features_deepchem = featurize_smiles(smiles)\n",
    "\n",
    "    # Generate Morgan Fingerprint (ECFP)\n",
    "    ecfp_features = generate_ecfp(smiles)\n",
    "\n",
    "    # Generate Molecule Graph Convolution features\n",
    "    mol_graph_node_features, mol_graph_edge_features, mol_graph_edge_index = (\n",
    "        smiles_to_graph_featurizer(smiles)\n",
    "    )\n",
    "\n",
    "    # Nodes (atoms)\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_features(atom, ecfp_features))\n",
    "\n",
    "    atom_features_list = np.array(atom_features_list)\n",
    "\n",
    "    # Edges (bonds)\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        # Append bidirectional edges for undirected graphs\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "\n",
    "        # Append bond features for both directions\n",
    "        edge_attr.append(bond_features(bond))\n",
    "        edge_attr.append(bond_features(bond))\n",
    "\n",
    "    # Convert atom features to a tensor\n",
    "    combined_features = np.concatenate(\n",
    "        (atom_features_list, atom_features_deepchem, mol_graph_node_features), axis=1\n",
    "    )\n",
    "    x = torch.tensor(combined_features, dtype=torch.float)\n",
    "\n",
    "    # Convert edge indices and features to tensors, handle empty edge case\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # combine edge features from ECFP and MolGraphConv\n",
    "    edge_attr = np.array(edge_attr)\n",
    "    edge_attr = np.concatenate((edge_attr, mol_graph_edge_features), axis=1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Label (target)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "\n",
    "# Function to load data from parquet and apply SMILES augmentation for training\n",
    "def load_data_from_parquet(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    smiles_list = df[\"Smiles\"].values\n",
    "    labels = df[\"Liver\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0).values\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    # Initialize the SmilesEnumerator for data augmentation\n",
    "    for smiles, label in zip(smiles_list, labels):\n",
    "        # For test data, no augmentation, just use canonical SMILES\n",
    "        graph_data = smiles_to_graph(smiles, label)\n",
    "        data_list.append(graph_data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "data1 = load_data_from_parquet(\"data/training_class_mixed.parquet\")\n",
    "data2 = load_data_from_parquet(\"data/testing_class_mixed.parquet\")\n",
    "dataset = data1 + data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "data_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_features,\n",
    "        num_classes,\n",
    "        num_layers=3,\n",
    "        hidden_dim=64,\n",
    "        dropout_prob=0.5,\n",
    "        activation=\"relu\",\n",
    "    ):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Store activation function dynamically\n",
    "        if activation == \"relu\":\n",
    "            self.activation = F.relu\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = F.tanh\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Dynamically define the GCN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(num_node_features, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Final fully connected layer\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Apply GCN layers dynamically\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation(x)\n",
    "\n",
    "        # Global pooling (combine different pooling methods)\n",
    "        x = torch.cat([global_mean_pool(x, batch), global_add_pool(x, batch)], dim=1)\n",
    "\n",
    "        # Apply dropout\n",
    "        x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
    "\n",
    "        # Final classification layer\n",
    "        return F.log_softmax(self.fc(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter Suggestions\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\"])\n",
    "    dropout_prob = trial.suggest_float(\"dropout_prob\", 0.1, 0.7)\n",
    "\n",
    "    # Get number of features and classes\n",
    "    num_node_features = 70\n",
    "    num_classes = 2\n",
    "\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y = [data.y.item() for data in dataset]\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(np.zeros(len(dataset)), y):\n",
    "        train_dataset = [dataset[i] for i in train_idx]\n",
    "        test_dataset = [dataset[i] for i in test_idx]\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize Model\n",
    "        model = GCN(\n",
    "            num_node_features=num_node_features,\n",
    "            num_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_prob=dropout_prob,\n",
    "            activation=activation,\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for epoch in range(50):  # Fixed number of epochs\n",
    "            for batch in train_loader:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = criterion(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(batch)\n",
    "            y_true.append(batch.y.cpu().numpy())\n",
    "            y_pred.append(out[:, 1].cpu().numpy())  # Assuming binary classification\n",
    "\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Return Mean AUC\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "  Value: 0.7554475138121548\n",
      "  Params: \n",
      "    hidden_dim: 231\n",
      "    dropout_prob: 0.3543332425071246\n",
      "    lr: 0.0007656402736244026\n",
      "    weight_decay: 1.7118701796851756e-05\n",
      "    num_layers: 4\n",
      "    activation: relu\n"
     ]
    }
   ],
   "source": [
    "# Output the best parameters and score\n",
    "print(\"Best AUC Score:\", study.best_value)\n",
    "print(\"Best Hyperparameters:\", study.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
