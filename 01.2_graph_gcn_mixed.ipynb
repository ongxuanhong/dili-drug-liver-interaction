{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No normalization for SPS. Feature removed!\n",
      "No normalization for AvgIpc. Feature removed!\n",
      "Skipped loading some Tensorflow models, missing a dependency. No module named 'tensorflow'\n",
      "Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'dgl'\n",
      "Skipped loading modules with transformers dependency. No module named 'transformers'\n",
      "cannot import name 'HuggingFaceModel' from 'deepchem.models.torch_models' (/home/m12gbs1/miniconda3/envs/dili/lib/python3.9/site-packages/deepchem/models/torch_models/__init__.py)\n",
      "Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
      "Skipped loading some Jax models, missing a dependency. No module named 'jax'\n",
      "Skipped loading some PyTorch models, missing a dependency. No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_add_pool\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from rdkit.Chem import rdFingerprintGenerator\n",
    "import deepchem as dc\n",
    "import optuna\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing SMILES Data into Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize_smiles(smiles):\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "    graph_data = featurizer.featurize([smiles])[0]\n",
    "\n",
    "    # Get DeepChem atom features\n",
    "    atom_features_deepchem = graph_data.node_features\n",
    "\n",
    "    return atom_features_deepchem\n",
    "\n",
    "\n",
    "# Function to generate Morgan Fingerprints (ECFP)\n",
    "def generate_ecfp(smiles):\n",
    "    # Morgan fingerprint generator\n",
    "    mfgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=4096)\n",
    "\n",
    "    molecule = Chem.MolFromSmiles(smiles)\n",
    "    if molecule is None:\n",
    "        return None\n",
    "    return mfgen.GetFingerprintAsNumPy(molecule)\n",
    "\n",
    "\n",
    "# Function to convert SMILES to PyTorch Geometric Data object using DeepChem featurizer\n",
    "def smiles_to_graph_featurizer(smiles):\n",
    "    # Featurization using DeepChem\n",
    "    featurizer = dc.feat.MolGraphConvFeaturizer(use_edges=True)\n",
    "\n",
    "    # Featurize the SMILES string using DeepChem\n",
    "    graph_data = featurizer.featurize([smiles])[0]\n",
    "    return graph_data.node_features, graph_data.edge_features, graph_data.edge_index\n",
    "\n",
    "\n",
    "# Function to extract atom features\n",
    "def atom_features(atom, ecfp):\n",
    "    # Get the atom index for corresponding ECFP value\n",
    "    atom_idx = atom.GetIdx()\n",
    "\n",
    "    return [\n",
    "        atom.GetAtomicNum(),  # Atomic number\n",
    "        atom.GetDegree(),  # Number of bonds\n",
    "        atom.GetTotalNumHs(),  # Total number of hydrogens\n",
    "        atom.GetFormalCharge(),  # Formal charge of the atom\n",
    "        atom.GetImplicitValence(),  # Implicit valence\n",
    "        atom.GetNumRadicalElectrons(),  # Number of radical electrons\n",
    "        int(atom.GetIsAromatic()),  # Is the atom aromatic?\n",
    "        atom.GetMass(),  # Atomic mass\n",
    "        atom.GetHybridization().real,  # Hybridization state (SP, SP2, SP3, etc.)\n",
    "        ecfp[atom_idx],  # Morgan fingerprint (ECFP) for the atom\n",
    "    ]\n",
    "\n",
    "\n",
    "# Function to extract bond features\n",
    "def bond_features(bond):\n",
    "    bond_type = bond.GetBondTypeAsDouble()  # Bond type as a float\n",
    "    is_aromatic = bond.GetIsAromatic()  # Aromatic bond\n",
    "    is_conjugated = bond.GetIsConjugated()  # Conjugated bond\n",
    "    is_in_ring = bond.IsInRing()  # Whether the bond is part of a ring\n",
    "    stereo = bond.GetStereo()  # Bond stereochemistry\n",
    "\n",
    "    # Convert stereo information to a one-hot encoded format\n",
    "    stereo_one_hot = [0, 0, 0, 0]  # Stereo options: None, E, Z, Other\n",
    "    if stereo == Chem.BondStereo.STEREONONE:\n",
    "        stereo_one_hot[0] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOE:\n",
    "        stereo_one_hot[1] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOZ:\n",
    "        stereo_one_hot[2] = 1\n",
    "    else:\n",
    "        stereo_one_hot[3] = 1\n",
    "\n",
    "    # Combine all features into a single tensor\n",
    "    return [\n",
    "        bond_type,\n",
    "        float(is_aromatic),\n",
    "        float(is_conjugated),\n",
    "        float(is_in_ring),\n",
    "    ] + stereo_one_hot\n",
    "\n",
    "\n",
    "# Convert SMILES to PyTorch Geometric Data object\n",
    "def smiles_to_graph(smiles, label):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    atom_features_list = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    # DeepChem features\n",
    "    atom_features_deepchem = featurize_smiles(smiles)\n",
    "\n",
    "    # Generate Morgan Fingerprint (ECFP)\n",
    "    ecfp_features = generate_ecfp(smiles)\n",
    "\n",
    "    # Generate Molecule Graph Convolution features\n",
    "    mol_graph_node_features, mol_graph_edge_features, mol_graph_edge_index = (\n",
    "        smiles_to_graph_featurizer(smiles)\n",
    "    )\n",
    "\n",
    "    # Nodes (atoms)\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_features(atom, ecfp_features))\n",
    "\n",
    "    atom_features_list = np.array(atom_features_list)\n",
    "\n",
    "    # Edges (bonds)\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "\n",
    "        # Append bidirectional edges for undirected graphs\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "\n",
    "        # Append bond features for both directions\n",
    "        edge_attr.append(bond_features(bond))\n",
    "        edge_attr.append(bond_features(bond))\n",
    "\n",
    "    # Convert atom features to a tensor\n",
    "    combined_features = np.concatenate(\n",
    "        (atom_features_list, atom_features_deepchem, mol_graph_node_features), axis=1\n",
    "    )\n",
    "    x = torch.tensor(combined_features, dtype=torch.float)\n",
    "\n",
    "    # Convert edge indices and features to tensors, handle empty edge case\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # combine edge features from ECFP and MolGraphConv\n",
    "    edge_attr = np.array(edge_attr)\n",
    "    edge_attr = np.concatenate((edge_attr, mol_graph_edge_features), axis=1)\n",
    "    edge_attr = torch.tensor(edge_attr, dtype=torch.float)\n",
    "\n",
    "    # Label (target)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "\n",
    "# Function to load data from parquet and apply SMILES augmentation for training\n",
    "def load_data_from_parquet(file_path):\n",
    "    df = pd.read_parquet(file_path)\n",
    "\n",
    "    smiles_list = df[\"Smiles\"].values\n",
    "    labels = df[\"Liver\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0).values\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    # Initialize the SmilesEnumerator for data augmentation\n",
    "    for smiles, label in zip(smiles_list, labels):\n",
    "        # For test data, no augmentation, just use canonical SMILES\n",
    "        graph_data = smiles_to_graph(smiles, label)\n",
    "        data_list.append(graph_data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "# data1 = load_data_from_parquet(\"data/training_class_mixed.parquet\")\n",
    "# data2 = load_data_from_parquet(\"data/testing_class_mixed.parquet\")\n",
    "# dataset = data1 + data2\n",
    "\n",
    "training_data = load_data_from_parquet(\"data/training_class_mixed.parquet\")\n",
    "testing_data = load_data_from_parquet(\"data/testing_class_mixed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_node_features,\n",
    "        num_classes,\n",
    "        num_layers=3,\n",
    "        hidden_dim=64,\n",
    "        dropout_prob=0.5,\n",
    "        activation=\"relu\",\n",
    "    ):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Store activation function dynamically\n",
    "        if activation == \"relu\":\n",
    "            self.activation = F.relu\n",
    "        elif activation == \"tanh\":\n",
    "            self.activation = F.tanh\n",
    "        elif activation == \"leaky_relu\":\n",
    "            self.activation = F.leaky_relu\n",
    "        elif activation == \"sigmoid\":\n",
    "            self.activation = torch.sigmoid\n",
    "        elif activation == \"elu\":\n",
    "            self.activation = F.elu\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "        self.dropout_prob = dropout_prob\n",
    "\n",
    "        # Dynamically define the GCN layers\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(num_node_features, hidden_dim))\n",
    "        for _ in range(num_layers - 1):\n",
    "            self.convs.append(GCNConv(hidden_dim, hidden_dim))\n",
    "\n",
    "        # Final fully connected layer\n",
    "        self.fc = torch.nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # Apply GCN layers dynamically\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            x = self.activation(x)\n",
    "\n",
    "        # Global pooling (combine different pooling methods)\n",
    "        x = torch.cat([global_mean_pool(x, batch), global_add_pool(x, batch)], dim=1)\n",
    "\n",
    "        # Apply dropout\n",
    "        x = F.dropout(x, p=self.dropout_prob, training=self.training)\n",
    "\n",
    "        # Final classification layer\n",
    "        return F.log_softmax(self.fc(x), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Initialize global variables to store the best model and its AUC\n",
    "best_model = None\n",
    "best_model_auc = {\"auc\": 0.0}\n",
    "best_params = {}\n",
    "\n",
    "def objective(trial):\n",
    "    # Hyperparameter Suggestions\n",
    "    hidden_dim = trial.suggest_int(\"hidden_dim\", 16, 128)\n",
    "    num_layers = trial.suggest_int(\"num_layers\", 2, 4)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-4, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-5, 1e-3, log=True)\n",
    "    activation = trial.suggest_categorical(\"activation\", [\"relu\", \"tanh\", \"leaky_relu\", \"sigmoid\", \"elu\"])\n",
    "    dropout_prob = trial.suggest_float(\"dropout_prob\", 0.1, 0.7)\n",
    "\n",
    "    # Get number of features and classes\n",
    "    num_node_features = 70\n",
    "    num_classes = 2\n",
    "\n",
    "    # Device setup\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    y = [data.y.item() for data in training_data]\n",
    "    auc_scores = []\n",
    "\n",
    "    for train_idx, test_idx in skf.split(np.zeros(len(training_data)), y):\n",
    "        train_dataset = [training_data[i] for i in train_idx]\n",
    "        test_dataset = [training_data[i] for i in test_idx]\n",
    "\n",
    "        train_loader_i = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader_i = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize Model\n",
    "        model = GCN(\n",
    "            num_node_features=num_node_features,\n",
    "            num_classes=num_classes,\n",
    "            num_layers=num_layers,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_prob=dropout_prob,\n",
    "            activation=activation,\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer = torch.optim.Adam(\n",
    "            model.parameters(), lr=learning_rate, weight_decay=weight_decay\n",
    "        )\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "        # Training\n",
    "        model.train()\n",
    "        for epoch in range(50):  # Fixed number of epochs\n",
    "            for batch in train_loader_i:\n",
    "                batch = batch.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                out = model(batch)\n",
    "                loss = criterion(out, batch.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        y_true, y_pred = [], []\n",
    "        for batch in test_loader_i:\n",
    "            batch = batch.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(batch)\n",
    "            y_true.append(batch.y.cpu().numpy())\n",
    "            y_pred.append(out[:, 1].cpu().numpy())  # Assuming binary classification\n",
    "\n",
    "        y_true = np.concatenate(y_true)\n",
    "        y_pred = np.concatenate(y_pred)\n",
    "        auc = roc_auc_score(y_true, y_pred)\n",
    "        auc_scores.append(auc)\n",
    "\n",
    "    # Save the best model\n",
    "    global best_model, best_model_auc, best_params\n",
    "    mean_auc = np.mean(auc_scores)\n",
    "    if mean_auc > best_model_auc[\"auc\"]:\n",
    "        best_model_auc[\"auc\"] = mean_auc\n",
    "        best_model = model\n",
    "        best_params = {\n",
    "            \"hidden_dim\": hidden_dim,\n",
    "            \"num_layers\": num_layers,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"weight_decay\": weight_decay,\n",
    "            \"activation\": activation,\n",
    "            \"dropout_prob\": dropout_prob,\n",
    "        }\n",
    "\n",
    "    # Return Mean AUC\n",
    "    return np.mean(auc_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-17 06:30:22,192] A new study created in memory with name: no-name-fe2f08ab-4590-4ee1-bba2-7fb68dd706eb\n",
      "[I 2024-11-17 06:30:36,813] Trial 0 finished with value: 0.6721713775687913 and parameters: {'hidden_dim': 106, 'num_layers': 2, 'learning_rate': 0.001116730093564706, 'weight_decay': 0.00011801495703239342, 'activation': 'leaky_relu', 'dropout_prob': 0.52676878850659}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:30:53,385] Trial 1 finished with value: 0.6534292493904563 and parameters: {'hidden_dim': 30, 'num_layers': 3, 'learning_rate': 0.0003555945819943349, 'weight_decay': 0.0006381931185043501, 'activation': 'tanh', 'dropout_prob': 0.5814426471239025}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:31:09,844] Trial 2 finished with value: 0.5033730755834205 and parameters: {'hidden_dim': 116, 'num_layers': 3, 'learning_rate': 0.006010304591289114, 'weight_decay': 7.859934538271497e-05, 'activation': 'sigmoid', 'dropout_prob': 0.3913710623199095}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:31:24,295] Trial 3 finished with value: 0.6338206199930339 and parameters: {'hidden_dim': 125, 'num_layers': 2, 'learning_rate': 0.00019245813427638833, 'weight_decay': 9.156173303095978e-05, 'activation': 'sigmoid', 'dropout_prob': 0.1545140534882851}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:31:42,873] Trial 4 finished with value: 0.663017284918147 and parameters: {'hidden_dim': 19, 'num_layers': 4, 'learning_rate': 0.00021560152437436508, 'weight_decay': 1.0251363990863135e-05, 'activation': 'leaky_relu', 'dropout_prob': 0.19165111525913953}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:32:01,555] Trial 5 finished with value: 0.6322011233019853 and parameters: {'hidden_dim': 102, 'num_layers': 4, 'learning_rate': 0.004402027651706332, 'weight_decay': 4.94009462116526e-05, 'activation': 'tanh', 'dropout_prob': 0.5079175350885795}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:32:20,314] Trial 6 finished with value: 0.6665488244514106 and parameters: {'hidden_dim': 96, 'num_layers': 4, 'learning_rate': 0.0012797501035212882, 'weight_decay': 1.7099860163387925e-05, 'activation': 'elu', 'dropout_prob': 0.3186063153636224}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:32:39,277] Trial 7 finished with value: 0.6555152211772902 and parameters: {'hidden_dim': 125, 'num_layers': 4, 'learning_rate': 0.0009992423121186157, 'weight_decay': 2.4343082973100406e-05, 'activation': 'elu', 'dropout_prob': 0.5036203331510236}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:32:53,820] Trial 8 finished with value: 0.6703517241379311 and parameters: {'hidden_dim': 29, 'num_layers': 2, 'learning_rate': 0.0013663085617570368, 'weight_decay': 0.00039974565429856754, 'activation': 'elu', 'dropout_prob': 0.6289623737126838}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:33:12,483] Trial 9 finished with value: 0.5080694618599791 and parameters: {'hidden_dim': 51, 'num_layers': 4, 'learning_rate': 0.0001614356552593099, 'weight_decay': 0.0002327079542586726, 'activation': 'sigmoid', 'dropout_prob': 0.5222983363219775}. Best is trial 0 with value: 0.6721713775687913.\n",
      "[I 2024-11-17 06:33:27,019] Trial 10 finished with value: 0.6759287704632533 and parameters: {'hidden_dim': 75, 'num_layers': 2, 'learning_rate': 0.002790889768899806, 'weight_decay': 0.0002853254771694548, 'activation': 'leaky_relu', 'dropout_prob': 0.29542141060066707}. Best is trial 10 with value: 0.6759287704632533.\n",
      "[I 2024-11-17 06:33:41,569] Trial 11 finished with value: 0.6718014454893766 and parameters: {'hidden_dim': 74, 'num_layers': 2, 'learning_rate': 0.002728508786937814, 'weight_decay': 0.00021135250584016562, 'activation': 'leaky_relu', 'dropout_prob': 0.32567352879706185}. Best is trial 10 with value: 0.6759287704632533.\n",
      "[I 2024-11-17 06:33:56,145] Trial 12 finished with value: 0.6669024033437827 and parameters: {'hidden_dim': 78, 'num_layers': 2, 'learning_rate': 0.0005836892794843232, 'weight_decay': 0.0002058104885821542, 'activation': 'leaky_relu', 'dropout_prob': 0.693102139079745}. Best is trial 10 with value: 0.6759287704632533.\n",
      "[I 2024-11-17 06:34:12,786] Trial 13 finished with value: 0.6647525165447579 and parameters: {'hidden_dim': 57, 'num_layers': 3, 'learning_rate': 0.0025421352617022836, 'weight_decay': 0.0009939370391403848, 'activation': 'relu', 'dropout_prob': 0.2448837944864891}. Best is trial 10 with value: 0.6759287704632533.\n",
      "[I 2024-11-17 06:34:27,623] Trial 14 finished with value: 0.6545423458725182 and parameters: {'hidden_dim': 93, 'num_layers': 2, 'learning_rate': 0.008991663952119911, 'weight_decay': 0.0001504430756154589, 'activation': 'leaky_relu', 'dropout_prob': 0.4242295037625068}. Best is trial 10 with value: 0.6759287704632533.\n",
      "[I 2024-11-17 06:34:42,304] Trial 15 finished with value: 0.6567062695924765 and parameters: {'hidden_dim': 60, 'num_layers': 2, 'learning_rate': 0.00259123237817184, 'weight_decay': 0.0003743163199317681, 'activation': 'leaky_relu', 'dropout_prob': 0.42420983476151536}. Best is trial 10 with value: 0.6759287704632533.\n",
      "[I 2024-11-17 06:34:58,992] Trial 16 finished with value: 0.678271952281435 and parameters: {'hidden_dim': 83, 'num_layers': 3, 'learning_rate': 0.0007672826203185937, 'weight_decay': 4.886856997631016e-05, 'activation': 'relu', 'dropout_prob': 0.2771540404114802}. Best is trial 16 with value: 0.678271952281435.\n",
      "[I 2024-11-17 06:35:15,675] Trial 17 finished with value: 0.6789972309299894 and parameters: {'hidden_dim': 84, 'num_layers': 3, 'learning_rate': 0.0006232775899296633, 'weight_decay': 4.4867639325120516e-05, 'activation': 'relu', 'dropout_prob': 0.10243624418462774}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:35:32,254] Trial 18 finished with value: 0.6687429205851619 and parameters: {'hidden_dim': 85, 'num_layers': 3, 'learning_rate': 0.0005144550647200853, 'weight_decay': 4.5050951639442145e-05, 'activation': 'relu', 'dropout_prob': 0.1272911467023896}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:35:48,826] Trial 19 finished with value: 0.67570228143504 and parameters: {'hidden_dim': 46, 'num_layers': 3, 'learning_rate': 0.00036160908993821723, 'weight_decay': 3.667796097751794e-05, 'activation': 'relu', 'dropout_prob': 0.21599007331231035}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:36:05,485] Trial 20 finished with value: 0.6754215952629746 and parameters: {'hidden_dim': 65, 'num_layers': 3, 'learning_rate': 0.00011259716776336942, 'weight_decay': 2.6088868153350158e-05, 'activation': 'relu', 'dropout_prob': 0.10499942243483096}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:36:22,149] Trial 21 finished with value: 0.6763526645768024 and parameters: {'hidden_dim': 83, 'num_layers': 3, 'learning_rate': 0.0007103697507531948, 'weight_decay': 6.42383886887402e-05, 'activation': 'relu', 'dropout_prob': 0.2686601304080539}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:36:38,936] Trial 22 finished with value: 0.669024416579589 and parameters: {'hidden_dim': 87, 'num_layers': 3, 'learning_rate': 0.0006724358674678548, 'weight_decay': 5.9452112851772746e-05, 'activation': 'relu', 'dropout_prob': 0.2677548643162553}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:36:55,600] Trial 23 finished with value: 0.6729880529432254 and parameters: {'hidden_dim': 84, 'num_layers': 3, 'learning_rate': 0.0003521275995724436, 'weight_decay': 7.774074023492644e-05, 'activation': 'relu', 'dropout_prob': 0.37218447402901567}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:37:12,129] Trial 24 finished with value: 0.6772717345872519 and parameters: {'hidden_dim': 67, 'num_layers': 3, 'learning_rate': 0.0008402786796067744, 'weight_decay': 3.127355159937684e-05, 'activation': 'relu', 'dropout_prob': 0.18757627683046937}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:37:28,663] Trial 25 finished with value: 0.6733202629745734 and parameters: {'hidden_dim': 68, 'num_layers': 3, 'learning_rate': 0.001748815402682666, 'weight_decay': 3.113612018186332e-05, 'activation': 'relu', 'dropout_prob': 0.1713165340494477}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:37:45,208] Trial 26 finished with value: 0.6741084900731451 and parameters: {'hidden_dim': 43, 'num_layers': 3, 'learning_rate': 0.0008551136454814416, 'weight_decay': 1.656669201517348e-05, 'activation': 'relu', 'dropout_prob': 0.21600520306955984}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:38:01,848] Trial 27 finished with value: 0.6726097526994078 and parameters: {'hidden_dim': 109, 'num_layers': 3, 'learning_rate': 0.0004713561987325961, 'weight_decay': 1.9703746744628573e-05, 'activation': 'relu', 'dropout_prob': 0.14004801307039208}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:38:18,443] Trial 28 finished with value: 0.6778752089864157 and parameters: {'hidden_dim': 95, 'num_layers': 3, 'learning_rate': 0.0017965264771659722, 'weight_decay': 1.115216688252367e-05, 'activation': 'relu', 'dropout_prob': 0.18881524836022004}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:38:37,158] Trial 29 finished with value: 0.6775376088470916 and parameters: {'hidden_dim': 104, 'num_layers': 4, 'learning_rate': 0.001821690645688057, 'weight_decay': 1.0127681761188197e-05, 'activation': 'tanh', 'dropout_prob': 0.10078397318612156}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:38:53,793] Trial 30 finished with value: 0.6672061650992684 and parameters: {'hidden_dim': 93, 'num_layers': 3, 'learning_rate': 0.0018798845727817021, 'weight_decay': 0.00012991513263256441, 'activation': 'relu', 'dropout_prob': 0.3568061027085959}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:39:12,595] Trial 31 finished with value: 0.6677679902473006 and parameters: {'hidden_dim': 113, 'num_layers': 4, 'learning_rate': 0.0016592567048063398, 'weight_decay': 1.2043663677692967e-05, 'activation': 'tanh', 'dropout_prob': 0.10240478496448303}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:39:31,371] Trial 32 finished with value: 0.6777544583768721 and parameters: {'hidden_dim': 102, 'num_layers': 4, 'learning_rate': 0.00123946039269794, 'weight_decay': 1.1988625682326416e-05, 'activation': 'tanh', 'dropout_prob': 0.14895811259699215}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:39:48,050] Trial 33 finished with value: 0.6785121386276559 and parameters: {'hidden_dim': 98, 'num_layers': 3, 'learning_rate': 0.00108862080955495, 'weight_decay': 1.4031930993154632e-05, 'activation': 'tanh', 'dropout_prob': 0.22569258652264426}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:40:04,665] Trial 34 finished with value: 0.659549259839777 and parameters: {'hidden_dim': 97, 'num_layers': 3, 'learning_rate': 0.00039766116295941273, 'weight_decay': 1.4451231955172418e-05, 'activation': 'tanh', 'dropout_prob': 0.21020109162213785}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:40:21,296] Trial 35 finished with value: 0.597965029606409 and parameters: {'hidden_dim': 119, 'num_layers': 3, 'learning_rate': 0.00024931792568287333, 'weight_decay': 2.4944533079020498e-05, 'activation': 'sigmoid', 'dropout_prob': 0.23631112706457094}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:40:37,896] Trial 36 finished with value: 0.672769540229885 and parameters: {'hidden_dim': 89, 'num_layers': 3, 'learning_rate': 0.0009758558231899292, 'weight_decay': 3.883584612565128e-05, 'activation': 'tanh', 'dropout_prob': 0.17605266847537854}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:40:54,626] Trial 37 finished with value: 0.6772502525252525 and parameters: {'hidden_dim': 79, 'num_layers': 3, 'learning_rate': 0.0002670741985097044, 'weight_decay': 0.0001072524204801603, 'activation': 'relu', 'dropout_prob': 0.28072813337087754}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:41:11,392] Trial 38 finished with value: 0.654985501567398 and parameters: {'hidden_dim': 110, 'num_layers': 3, 'learning_rate': 0.0034170243801729867, 'weight_decay': 1.974064769660684e-05, 'activation': 'elu', 'dropout_prob': 0.32724396253270077}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:41:28,214] Trial 39 finished with value: 0.5427675635667015 and parameters: {'hidden_dim': 98, 'num_layers': 3, 'learning_rate': 0.004769493288046384, 'weight_decay': 6.107369565358396e-05, 'activation': 'sigmoid', 'dropout_prob': 0.24013948957121875}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:41:45,063] Trial 40 finished with value: 0.672789237199582 and parameters: {'hidden_dim': 117, 'num_layers': 3, 'learning_rate': 0.001105000217821221, 'weight_decay': 1.4212951003551249e-05, 'activation': 'tanh', 'dropout_prob': 0.15652715085165692}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:42:03,771] Trial 41 finished with value: 0.6749281696273075 and parameters: {'hidden_dim': 106, 'num_layers': 4, 'learning_rate': 0.001262653588860735, 'weight_decay': 1.237349672294563e-05, 'activation': 'tanh', 'dropout_prob': 0.13917637766754898}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:42:22,629] Trial 42 finished with value: 0.6680110327412052 and parameters: {'hidden_dim': 101, 'num_layers': 4, 'learning_rate': 0.0014181731376041143, 'weight_decay': 2.2280584810383554e-05, 'activation': 'tanh', 'dropout_prob': 0.1901534694751033}. Best is trial 17 with value: 0.6789972309299894.\n",
      "[I 2024-11-17 06:42:39,191] Trial 43 finished with value: 0.6854492685475444 and parameters: {'hidden_dim': 92, 'num_layers': 3, 'learning_rate': 0.0007376684210691645, 'weight_decay': 1.2322840596113695e-05, 'activation': 'tanh', 'dropout_prob': 0.15206713363798266}. Best is trial 43 with value: 0.6854492685475444.\n",
      "[I 2024-11-17 06:42:55,690] Trial 44 finished with value: 0.6734336903517938 and parameters: {'hidden_dim': 90, 'num_layers': 3, 'learning_rate': 0.000758901987505166, 'weight_decay': 1.777867334330169e-05, 'activation': 'tanh', 'dropout_prob': 0.20778487308317783}. Best is trial 43 with value: 0.6854492685475444.\n",
      "[I 2024-11-17 06:43:12,233] Trial 45 finished with value: 0.6801092737722046 and parameters: {'hidden_dim': 82, 'num_layers': 3, 'learning_rate': 0.0005770834416330595, 'weight_decay': 1.000513537557411e-05, 'activation': 'elu', 'dropout_prob': 0.29788186982643095}. Best is trial 43 with value: 0.6854492685475444.\n",
      "[I 2024-11-17 06:43:29,298] Trial 46 finished with value: 0.6750136189481017 and parameters: {'hidden_dim': 79, 'num_layers': 3, 'learning_rate': 0.0005972994401154023, 'weight_decay': 1.5151832073854065e-05, 'activation': 'elu', 'dropout_prob': 0.28827588828181344}. Best is trial 43 with value: 0.6854492685475444.\n",
      "[I 2024-11-17 06:43:46,114] Trial 47 finished with value: 0.6721921804249391 and parameters: {'hidden_dim': 80, 'num_layers': 3, 'learning_rate': 0.0005754317752997833, 'weight_decay': 8.413529090139193e-05, 'activation': 'elu', 'dropout_prob': 0.45270587470598234}. Best is trial 43 with value: 0.6854492685475444.\n",
      "[I 2024-11-17 06:44:02,927] Trial 48 finished with value: 0.6764644636015326 and parameters: {'hidden_dim': 70, 'num_layers': 3, 'learning_rate': 0.00045968527360546396, 'weight_decay': 4.8052205014325097e-05, 'activation': 'elu', 'dropout_prob': 0.3066291784873589}. Best is trial 43 with value: 0.6854492685475444.\n",
      "[I 2024-11-17 06:44:17,612] Trial 49 finished with value: 0.6617818617206549 and parameters: {'hidden_dim': 75, 'num_layers': 2, 'learning_rate': 0.00028813431830276165, 'weight_decay': 2.954225971644168e-05, 'activation': 'elu', 'dropout_prob': 0.3364339675146209}. Best is trial 43 with value: 0.6854492685475444.\n"
     ]
    }
   ],
   "source": [
    "# Optuna Study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AUC Score: 0.6854492685475444\n",
      "Best Hyperparameters: {'hidden_dim': 92, 'num_layers': 3, 'learning_rate': 0.0007376684210691645, 'weight_decay': 1.2322840596113695e-05, 'activation': 'tanh', 'dropout_prob': 0.15206713363798266}\n"
     ]
    }
   ],
   "source": [
    "# Output the Best Parameters and AUC\n",
    "print(\"Best AUC Score:\", best_model_auc[\"auc\"])\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model as PyTorch and Joblib\n",
    "if best_model is not None:\n",
    "    torch.save(best_model.state_dict(), \"models_cv5/best_model_graph_gcn_mixed.pth\")  # Save PyTorch model\n",
    "    joblib.dump(best_params, \"models_cv5/best_model_params_graph_gcn_mixed.pkl\")      # Save parameters as Joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
