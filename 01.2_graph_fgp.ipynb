{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import (\n",
    "    GCNConv,\n",
    "    global_mean_pool,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "from torch.utils.data import Subset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing SMILES Data into Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract atom features\n",
    "def atom_features(atom):\n",
    "    return torch.tensor(\n",
    "        [\n",
    "            atom.GetAtomicNum(),            # Atomic number\n",
    "            atom.GetDegree(),               # Number of connected neighbors\n",
    "            atom.GetImplicitValence(),      # Implicit valence\n",
    "            atom.GetFormalCharge(),         # Formal charge\n",
    "            atom.GetIsAromatic(),           # Aromaticity\n",
    "        ],\n",
    "        dtype=torch.float,\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to extract bond features\n",
    "def bond_features(bond):\n",
    "    bond_type = bond.GetBondTypeAsDouble()            # Bond type as a float\n",
    "    is_aromatic = bond.GetIsAromatic()                # Aromatic bond\n",
    "    is_conjugated = bond.GetIsConjugated()            # Conjugated bond\n",
    "    is_in_ring = bond.IsInRing()                      # Whether the bond is part of a ring\n",
    "    stereo = bond.GetStereo()                         # Bond stereochemistry\n",
    "    \n",
    "    # Convert stereo information to a one-hot encoded format\n",
    "    stereo_one_hot = [0, 0, 0, 0]  # Stereo options: None, E, Z, Other\n",
    "    if stereo == Chem.BondStereo.STEREONONE:\n",
    "        stereo_one_hot[0] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOE:\n",
    "        stereo_one_hot[1] = 1\n",
    "    elif stereo == Chem.BondStereo.STEREOZ:\n",
    "        stereo_one_hot[2] = 1\n",
    "    else:\n",
    "        stereo_one_hot[3] = 1\n",
    "    \n",
    "    # Combine all features into a single tensor\n",
    "    return torch.tensor(\n",
    "        [bond_type, float(is_aromatic), float(is_conjugated), float(is_in_ring)] + stereo_one_hot, dtype=torch.float\n",
    "    )\n",
    "\n",
    "\n",
    "# Convert SMILES to PyTorch Geometric Data object\n",
    "def smiles_to_graph(smiles, label):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    atom_features_list = []\n",
    "    edge_index = []\n",
    "    edge_attr = []\n",
    "\n",
    "    # Nodes (atoms)\n",
    "    for atom in mol.GetAtoms():\n",
    "        atom_features_list.append(atom_features(atom))\n",
    "\n",
    "    # Edges (bonds)\n",
    "    for bond in mol.GetBonds():\n",
    "        i = bond.GetBeginAtomIdx()\n",
    "        j = bond.GetEndAtomIdx()\n",
    "        \n",
    "        # Append bidirectional edges for undirected graphs\n",
    "        edge_index.append([i, j])\n",
    "        edge_index.append([j, i])\n",
    "        \n",
    "        # Append bond features for both directions\n",
    "        edge_attr.append(bond_features(bond))\n",
    "        edge_attr.append(bond_features(bond))\n",
    "\n",
    "    # Convert atom features to a tensor\n",
    "    x = torch.stack(atom_features_list)\n",
    "\n",
    "    # Convert edge indices and features to tensors, handle empty edge case\n",
    "    if edge_index:\n",
    "        edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.stack(edge_attr)\n",
    "    else:\n",
    "        # Handle molecules with no bonds\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "        edge_attr = torch.empty((0,), dtype=torch.float)\n",
    "\n",
    "    # Label (target)\n",
    "    y = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "    return Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y)\n",
    "\n",
    "\n",
    "\n",
    "# Function to load data from CSV and apply SMILES augmentation for training\n",
    "def load_data_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    smiles_list = df[\"Smiles\"].values\n",
    "    labels = df[\"Liver\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0).values\n",
    "\n",
    "    data_list = []\n",
    "\n",
    "    # Initialize the SmilesEnumerator for data augmentation\n",
    "    for smiles, label in zip(smiles_list, labels):\n",
    "        # For test data, no augmentation, just use canonical SMILES\n",
    "        graph_data = smiles_to_graph(smiles, label)\n",
    "        data_list.append(graph_data)\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and testing data\n",
    "training_data = load_data_from_csv(\"data_smiles/Training_Group.csv\")\n",
    "testing_data = load_data_from_csv(\"data_smiles/Testing_Group.csv\")\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(training_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(testing_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[40, 5], edge_index=[2, 88], edge_attr=[88, 8], y=[1], batch=[40], ptr=[2])\n",
      "DataBatch(x=[15, 5], edge_index=[2, 30], edge_attr=[30, 8], y=[1], batch=[15], ptr=[2])\n",
      "DataBatch(x=[27, 5], edge_index=[2, 58], edge_attr=[58, 8], y=[1], batch=[27], ptr=[2])\n"
     ]
    }
   ],
   "source": [
    "# for i, data in enumerate(test_loader):\n",
    "#     print(data)\n",
    "\n",
    "#     if i == 2:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCN approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, hidden_channels):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        return F.log_softmax(self.fc(x), dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training Loop with Early Stopping and Metric Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the objective function for Optuna\n",
    "def objective(trial):\n",
    "    # Hyperparameters to tune\n",
    "    hidden_channels = trial.suggest_int('hidden_channels', 16, 128)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    weight_decay = trial.suggest_float('weight_decay', 1e-5, 1e-2, log=True)\n",
    "    \n",
    "    # Set up 5-fold cross-validation\n",
    "    num_epochs = 50\n",
    "    k_folds = 5\n",
    "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_data_from_csv(\"data_smiles/Training_Group.csv\")\n",
    "    num_node_features = 5\n",
    "    num_classes = 2\n",
    "    \n",
    "    fold_accuracies = []\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(dataset):\n",
    "        # Use Subset to split the dataset based on train and test indices\n",
    "        train_dataset = Subset(dataset, train_idx)\n",
    "        test_dataset = Subset(dataset, test_idx)\n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize the model, optimizer, and loss function\n",
    "        model = GCN(num_node_features, num_classes, hidden_channels)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            model.train()\n",
    "            for data in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                out = model(data)\n",
    "                loss = F.nll_loss(out, data.y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # Evaluation on test data\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in test_loader:\n",
    "                out = model(data)\n",
    "                pred = out.argmax(dim=1)\n",
    "                correct += (pred == data.y).sum().item()\n",
    "                total += data.y.size(0)\n",
    "        \n",
    "        fold_accuracies.append(correct / total)\n",
    "    \n",
    "    # Return the average accuracy across all folds\n",
    "    return sum(fold_accuracies) / len(fold_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-10-15 20:30:25,447] Trial 1 finished with value: 0.6018979142375956 and parameters: {'hidden_channels': 56, 'learning_rate': 0.00040116355330898517, 'weight_decay': 3.284779124451802e-05}. Best is trial 1 with value: 0.6018979142375956.\n",
      "[I 2024-10-15 20:31:08,393] Trial 2 finished with value: 0.6163848944163752 and parameters: {'hidden_channels': 72, 'learning_rate': 0.004960221156461526, 'weight_decay': 0.00020930099487375363}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:31:54,454] Trial 3 finished with value: 0.5793205078378028 and parameters: {'hidden_channels': 112, 'learning_rate': 7.942332796144281e-05, 'weight_decay': 0.0008252519892737347}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:32:41,235] Trial 4 finished with value: 0.6107624044565358 and parameters: {'hidden_channels': 117, 'learning_rate': 0.0003041727049453514, 'weight_decay': 1.9375522348387526e-05}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:33:24,948] Trial 5 finished with value: 0.6148011400440472 and parameters: {'hidden_channels': 62, 'learning_rate': 0.0014404736760496235, 'weight_decay': 0.00011741946092446309}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:34:09,160] Trial 6 finished with value: 0.6011011789091851 and parameters: {'hidden_channels': 87, 'learning_rate': 0.0022130451546008415, 'weight_decay': 0.0021575665290566814}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:34:50,457] Trial 7 finished with value: 0.614794662521052 and parameters: {'hidden_channels': 23, 'learning_rate': 0.009835918008581471, 'weight_decay': 1.6388040466467548e-05}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:35:35,590] Trial 8 finished with value: 0.6163687006088872 and parameters: {'hidden_channels': 78, 'learning_rate': 0.0034137346505409604, 'weight_decay': 1.4952449860885075e-05}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:36:19,174] Trial 9 finished with value: 0.6091559787537246 and parameters: {'hidden_channels': 72, 'learning_rate': 0.002853929271996899, 'weight_decay': 0.002103696073848894}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:37:00,849] Trial 10 finished with value: 0.5551820183961652 and parameters: {'hidden_channels': 36, 'learning_rate': 1.0913240049944202e-05, 'weight_decay': 0.0001121603385250654}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:37:44,352] Trial 11 finished with value: 0.5890011659541392 and parameters: {'hidden_channels': 96, 'learning_rate': 0.00831405085208077, 'weight_decay': 7.280770953726095e-05}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:38:25,068] Trial 12 finished with value: 0.5849818629356134 and parameters: {'hidden_channels': 48, 'learning_rate': 0.0010718628814973498, 'weight_decay': 0.0073553443106063494}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:39:10,310] Trial 13 finished with value: 0.6140205985231247 and parameters: {'hidden_channels': 91, 'learning_rate': 0.004499997581170294, 'weight_decay': 1.0098976761706863e-05}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:39:52,955] Trial 14 finished with value: 0.6139914496696464 and parameters: {'hidden_channels': 74, 'learning_rate': 0.0006381554192307393, 'weight_decay': 0.0003021494711523203}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:40:37,698] Trial 15 finished with value: 0.5785172949863971 and parameters: {'hidden_channels': 106, 'learning_rate': 8.954849219783097e-05, 'weight_decay': 4.7006995168770765e-05}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:41:20,333] Trial 16 finished with value: 0.6019173468065813 and parameters: {'hidden_channels': 38, 'learning_rate': 0.004584336922865714, 'weight_decay': 0.00024117396465989967}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:42:03,841] Trial 17 finished with value: 0.5809269335406141 and parameters: {'hidden_channels': 82, 'learning_rate': 0.00010060649137089271, 'weight_decay': 0.0008603706550332122}. Best is trial 2 with value: 0.6163848944163752.\n",
      "[I 2024-10-15 20:42:47,368] Trial 18 finished with value: 0.6300913330742325 and parameters: {'hidden_channels': 101, 'learning_rate': 0.004518281718061897, 'weight_decay': 3.392030089128654e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:43:33,934] Trial 19 finished with value: 0.5519529731830548 and parameters: {'hidden_channels': 126, 'learning_rate': 1.4430695606490198e-05, 'weight_decay': 0.00017149707999480733}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:44:20,121] Trial 20 finished with value: 0.6051140044047156 and parameters: {'hidden_channels': 102, 'learning_rate': 0.0010393283155585415, 'weight_decay': 4.509990202310209e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:45:03,300] Trial 21 finished with value: 0.6131688042492551 and parameters: {'hidden_channels': 62, 'learning_rate': 0.004798685336436188, 'weight_decay': 2.7401231400984184e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:45:56,441] Trial 22 finished with value: 0.6292816426998316 and parameters: {'hidden_channels': 83, 'learning_rate': 0.0021696468944556726, 'weight_decay': 1.4384523141321087e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:46:41,085] Trial 23 finished with value: 0.6067269076305221 and parameters: {'hidden_channels': 96, 'learning_rate': 0.002031790720156884, 'weight_decay': 6.012629476935795e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:47:29,437] Trial 24 finished with value: 0.6026914108045084 and parameters: {'hidden_channels': 84, 'learning_rate': 0.009787709709757904, 'weight_decay': 0.000594587600032227}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:48:35,390] Trial 25 finished with value: 0.626862287861122 and parameters: {'hidden_channels': 66, 'learning_rate': 0.00604683531387062, 'weight_decay': 1.1120748832074638e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:49:41,934] Trial 26 finished with value: 0.6115818111154294 and parameters: {'hidden_channels': 58, 'learning_rate': 0.0016485857967970033, 'weight_decay': 1.0084629116104296e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:50:52,183] Trial 27 finished with value: 0.6188074880165825 and parameters: {'hidden_channels': 128, 'learning_rate': 0.0007433524682943368, 'weight_decay': 2.4042067922002323e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:51:40,886] Trial 28 finished with value: 0.6220624433216738 and parameters: {'hidden_channels': 101, 'learning_rate': 0.0059617130187016795, 'weight_decay': 3.3647238073591485e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:52:24,371] Trial 29 finished with value: 0.5898076175670424 and parameters: {'hidden_channels': 66, 'learning_rate': 0.00015908916217331304, 'weight_decay': 1.4198578984532109e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:53:17,813] Trial 30 finished with value: 0.6131752817722503 and parameters: {'hidden_channels': 45, 'learning_rate': 0.0028337770222275015, 'weight_decay': 9.137833963924834e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:54:34,220] Trial 31 finished with value: 0.6236526752169971 and parameters: {'hidden_channels': 104, 'learning_rate': 0.006241049741983814, 'weight_decay': 3.619370818766899e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:55:48,797] Trial 32 finished with value: 0.6292881202228268 and parameters: {'hidden_channels': 115, 'learning_rate': 0.007061973648733846, 'weight_decay': 3.221525765237101e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:57:01,706] Trial 33 finished with value: 0.6300816167897396 and parameters: {'hidden_channels': 115, 'learning_rate': 0.0031823966818490504, 'weight_decay': 2.2087822814769614e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:57:55,712] Trial 34 finished with value: 0.6051140044047156 and parameters: {'hidden_channels': 120, 'learning_rate': 0.0004330910948083549, 'weight_decay': 2.3285882329429857e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 20:59:37,207] Trial 35 finished with value: 0.6228462236040938 and parameters: {'hidden_channels': 113, 'learning_rate': 0.0030728274561947983, 'weight_decay': 5.485723822312582e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:01:33,405] Trial 36 finished with value: 0.6083398108563285 and parameters: {'hidden_channels': 111, 'learning_rate': 0.0011480151123757381, 'weight_decay': 2.293600856790079e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:03:04,680] Trial 37 finished with value: 0.617178390983288 and parameters: {'hidden_channels': 120, 'learning_rate': 0.002072647416433231, 'weight_decay': 3.3987997055648546e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:03:52,265] Trial 38 finished with value: 0.5962495141857753 and parameters: {'hidden_channels': 94, 'learning_rate': 0.003633712291996155, 'weight_decay': 0.00015773758515093874}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:04:40,994] Trial 39 finished with value: 0.6059334110636093 and parameters: {'hidden_channels': 109, 'learning_rate': 0.0067098481962347516, 'weight_decay': 1.6612330935161313e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:05:28,991] Trial 40 finished with value: 0.5720753983676642 and parameters: {'hidden_channels': 116, 'learning_rate': 5.007760877193184e-05, 'weight_decay': 6.85999477614224e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:06:14,864] Trial 41 finished with value: 0.6107462106490479 and parameters: {'hidden_channels': 89, 'learning_rate': 0.007143154392368691, 'weight_decay': 1.2226278323887064e-05}. Best is trial 18 with value: 0.6300913330742325.\n",
      "[I 2024-10-15 21:06:59,554] Trial 42 finished with value: 0.6357332556030574 and parameters: {'hidden_channels': 80, 'learning_rate': 0.003477833496936736, 'weight_decay': 1.8809161976703587e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:07:44,785] Trial 43 finished with value: 0.610752688172043 and parameters: {'hidden_channels': 78, 'learning_rate': 0.0014869768130342975, 'weight_decay': 1.7788971315874852e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:08:32,642] Trial 44 finished with value: 0.6252591009198083 and parameters: {'hidden_channels': 98, 'learning_rate': 0.0023361982818912047, 'weight_decay': 4.1593368401614695e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:09:26,827] Trial 45 finished with value: 0.6284719523254308 and parameters: {'hidden_channels': 123, 'learning_rate': 0.003610053765904326, 'weight_decay': 1.7319777503238964e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:10:14,339] Trial 46 finished with value: 0.6018784816686099 and parameters: {'hidden_channels': 108, 'learning_rate': 0.0038137976120407356, 'weight_decay': 2.791134753971463e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:10:56,962] Trial 47 finished with value: 0.5906205467029408 and parameters: {'hidden_channels': 18, 'learning_rate': 0.0007229348022490614, 'weight_decay': 8.58897108067289e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:11:41,847] Trial 48 finished with value: 0.6268655266226195 and parameters: {'hidden_channels': 85, 'learning_rate': 0.002610763394893633, 'weight_decay': 2.184933736764931e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:12:28,388] Trial 49 finished with value: 0.6236494364554994 and parameters: {'hidden_channels': 79, 'learning_rate': 0.009821661803536368, 'weight_decay': 1.4310675728904164e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:13:17,124] Trial 50 finished with value: 0.6292913589843244 and parameters: {'hidden_channels': 114, 'learning_rate': 0.004792712235837079, 'weight_decay': 0.0001262205681205084}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:14:06,071] Trial 51 finished with value: 0.6268752429071123 and parameters: {'hidden_channels': 118, 'learning_rate': 0.004554390323620993, 'weight_decay': 0.0001242113411387562}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:14:54,576] Trial 52 finished with value: 0.6317042363000389 and parameters: {'hidden_channels': 115, 'learning_rate': 0.008055384368703773, 'weight_decay': 3.3495027481769285e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:15:42,295] Trial 53 finished with value: 0.6212300816167897 and parameters: {'hidden_channels': 116, 'learning_rate': 0.00811679482408703, 'weight_decay': 4.9351142618833175e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:16:30,636] Trial 54 finished with value: 0.6212462754242777 and parameters: {'hidden_channels': 123, 'learning_rate': 0.004709753694680209, 'weight_decay': 0.00046695830429372304}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:17:20,800] Trial 55 finished with value: 0.5503433087187459 and parameters: {'hidden_channels': 111, 'learning_rate': 0.0055373433255561716, 'weight_decay': 0.009533412760816136}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:18:09,828] Trial 56 finished with value: 0.596236559139785 and parameters: {'hidden_channels': 114, 'learning_rate': 0.008050367170886408, 'weight_decay': 3.1581045885212704e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:18:58,152] Trial 57 finished with value: 0.593010752688172 and parameters: {'hidden_channels': 105, 'learning_rate': 0.0038759800267291933, 'weight_decay': 0.0014910830135888796}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:19:44,167] Trial 58 finished with value: 0.5954527788573649 and parameters: {'hidden_channels': 93, 'learning_rate': 0.0017822813959761524, 'weight_decay': 0.004664521446715766}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:20:33,392] Trial 59 finished with value: 0.6172075398367665 and parameters: {'hidden_channels': 125, 'learning_rate': 0.003112898404563969, 'weight_decay': 7.577525443568614e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:21:19,601] Trial 60 finished with value: 0.5898076175670424 and parameters: {'hidden_channels': 101, 'learning_rate': 0.00022681139306153324, 'weight_decay': 3.9997421500606814e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:22:04,076] Trial 61 finished with value: 0.6188139655395777 and parameters: {'hidden_channels': 73, 'learning_rate': 0.005412060450587651, 'weight_decay': 2.1204180578364604e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:22:49,885] Trial 62 finished with value: 0.6123591138748542 and parameters: {'hidden_channels': 99, 'learning_rate': 0.0012360304520668667, 'weight_decay': 1.2977787309713346e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:23:36,863] Trial 63 finished with value: 0.6308945459256381 and parameters: {'hidden_channels': 107, 'learning_rate': 0.007215001215343857, 'weight_decay': 2.7157218078258076e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:24:33,872] Trial 64 finished with value: 0.6276914108045084 and parameters: {'hidden_channels': 107, 'learning_rate': 0.00765985907125049, 'weight_decay': 2.681373257810903e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:25:49,213] Trial 65 finished with value: 0.6155816815649695 and parameters: {'hidden_channels': 119, 'learning_rate': 0.00929846971913429, 'weight_decay': 5.836246792172428e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:27:04,830] Trial 66 finished with value: 0.5583916310402902 and parameters: {'hidden_channels': 113, 'learning_rate': 3.0682182975118464e-05, 'weight_decay': 0.0002577322572774957}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:28:18,589] Trial 67 finished with value: 0.6260590750097162 and parameters: {'hidden_channels': 110, 'learning_rate': 0.006844636455890005, 'weight_decay': 2.958405366780057e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:29:33,736] Trial 68 finished with value: 0.6244688431143931 and parameters: {'hidden_channels': 122, 'learning_rate': 0.0045938199128142424, 'weight_decay': 1.9416162589661293e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:30:48,890] Trial 69 finished with value: 0.61802694649566 and parameters: {'hidden_channels': 127, 'learning_rate': 0.002745046911455236, 'weight_decay': 0.00012308460457241763}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:32:02,319] Trial 70 finished with value: 0.6171848685062832 and parameters: {'hidden_channels': 105, 'learning_rate': 0.00509161111736898, 'weight_decay': 4.339018639257545e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:32:50,816] Trial 71 finished with value: 0.6252817722502916 and parameters: {'hidden_channels': 91, 'learning_rate': 0.003984362839507486, 'weight_decay': 1.558729323573898e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:33:34,730] Trial 72 finished with value: 0.6131558492032647 and parameters: {'hidden_channels': 81, 'learning_rate': 0.0022280503380027175, 'weight_decay': 3.517419245986292e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:34:18,861] Trial 73 finished with value: 0.6236397201710066 and parameters: {'hidden_channels': 68, 'learning_rate': 0.006255884251079554, 'weight_decay': 1.2118937327759155e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:35:03,048] Trial 74 finished with value: 0.626884959191605 and parameters: {'hidden_channels': 88, 'learning_rate': 0.0032506146133361464, 'weight_decay': 2.4554641395300108e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:35:47,832] Trial 75 finished with value: 0.6139655395776655 and parameters: {'hidden_channels': 76, 'learning_rate': 0.005675022100500004, 'weight_decay': 1.9326763849474128e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:36:54,570] Trial 76 finished with value: 0.6059139784946236 and parameters: {'hidden_channels': 115, 'learning_rate': 0.0018124585903526514, 'weight_decay': 5.189874036961443e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:38:05,093] Trial 77 finished with value: 0.6220494882756833 and parameters: {'hidden_channels': 103, 'learning_rate': 0.007070613392497337, 'weight_decay': 1.0041717909668715e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:39:17,363] Trial 78 finished with value: 0.6035075787019044 and parameters: {'hidden_channels': 95, 'learning_rate': 0.00046831639110903766, 'weight_decay': 0.00017868696993587855}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:40:07,177] Trial 79 finished with value: 0.6148011400440472 and parameters: {'hidden_channels': 69, 'learning_rate': 0.002572268453206719, 'weight_decay': 6.178375762563686e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:41:11,181] Trial 80 finished with value: 0.6268720041456147 and parameters: {'hidden_channels': 98, 'learning_rate': 0.004071196488101489, 'weight_decay': 9.511668696239581e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:42:25,591] Trial 81 finished with value: 0.6236429589325042 and parameters: {'hidden_channels': 123, 'learning_rate': 0.0031131408012804052, 'weight_decay': 1.5886620219346943e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:43:39,006] Trial 82 finished with value: 0.6309010234486332 and parameters: {'hidden_channels': 121, 'learning_rate': 0.003502088257805594, 'weight_decay': 1.7060173287814168e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:44:48,168] Trial 83 finished with value: 0.6011238502396684 and parameters: {'hidden_channels': 118, 'learning_rate': 0.009581138992306861, 'weight_decay': 2.7418456008827426e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:45:56,831] Trial 84 finished with value: 0.6083171395258453 and parameters: {'hidden_channels': 108, 'learning_rate': 0.00536300567894418, 'weight_decay': 3.958633231032306e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:47:09,820] Trial 85 finished with value: 0.6204139137193938 and parameters: {'hidden_channels': 120, 'learning_rate': 0.002243205419727722, 'weight_decay': 2.1935694314522294e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:48:14,787] Trial 86 finished with value: 0.6284849073714212 and parameters: {'hidden_channels': 112, 'learning_rate': 0.003579697864503585, 'weight_decay': 1.3644221323920622e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:49:01,967] Trial 87 finished with value: 0.6268655266226195 and parameters: {'hidden_channels': 116, 'learning_rate': 0.008376074650969354, 'weight_decay': 1.833283094463931e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:49:49,979] Trial 88 finished with value: 0.6115656173079416 and parameters: {'hidden_channels': 128, 'learning_rate': 0.001468070145143777, 'weight_decay': 2.9996541920247845e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:50:33,265] Trial 89 finished with value: 0.6067204301075269 and parameters: {'hidden_channels': 29, 'learning_rate': 0.004589478272790737, 'weight_decay': 2.4976755574212788e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:51:39,804] Trial 90 finished with value: 0.6131461329187718 and parameters: {'hidden_channels': 111, 'learning_rate': 0.0060578119971841605, 'weight_decay': 3.5041246568994164e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:52:41,952] Trial 91 finished with value: 0.6188010104935873 and parameters: {'hidden_channels': 85, 'learning_rate': 0.0033354367721316123, 'weight_decay': 1.4456285277732718e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:53:55,711] Trial 92 finished with value: 0.6276752169970203 and parameters: {'hidden_channels': 112, 'learning_rate': 0.003955035130617485, 'weight_decay': 1.3720662731446182e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:55:11,284] Trial 93 finished with value: 0.6260590750097164 and parameters: {'hidden_channels': 114, 'learning_rate': 0.002657112863352996, 'weight_decay': 1.9343797896103048e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:56:19,324] Trial 94 finished with value: 0.6147881849980568 and parameters: {'hidden_channels': 107, 'learning_rate': 0.0076111067993343265, 'weight_decay': 1.0732319574388431e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:57:33,033] Trial 95 finished with value: 0.6026914108045085 and parameters: {'hidden_channels': 125, 'learning_rate': 0.000945754633915883, 'weight_decay': 1.1571311671879047e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 21:58:43,847] Trial 96 finished with value: 0.6099429977976422 and parameters: {'hidden_channels': 52, 'learning_rate': 0.0020043456163079242, 'weight_decay': 1.662711494588313e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 22:00:03,588] Trial 97 finished with value: 0.6252526233968131 and parameters: {'hidden_channels': 117, 'learning_rate': 0.00429170803267591, 'weight_decay': 2.138408327000464e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 22:01:21,813] Trial 98 finished with value: 0.6284881461329188 and parameters: {'hidden_channels': 101, 'learning_rate': 0.005198164554005784, 'weight_decay': 3.2640329595304146e-05}. Best is trial 42 with value: 0.6357332556030574.\n",
      "[I 2024-10-15 22:02:42,113] Trial 99 finished with value: 0.6196236559139786 and parameters: {'hidden_channels': 121, 'learning_rate': 0.005028590151392645, 'weight_decay': 4.548688589950873e-05}. Best is trial 42 with value: 0.6357332556030574.\n"
     ]
    }
   ],
   "source": [
    "# Set up the Optuna study and run optimization\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial:\n",
      "AUC: 0.6357332556030574\n",
      "Best hyperparameters: {'hidden_channels': 80, 'learning_rate': 0.003477833496936736, 'weight_decay': 1.8809161976703587e-05}\n"
     ]
    }
   ],
   "source": [
    "# To print the best trial's hyperparameters\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "print(f\"AUC: {trial.value}\")\n",
    "print(f\"Best hyperparameters: {trial.params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "# Define the function to train and evaluate the model based on the best parameters\n",
    "def evaluate_best_model(best_params, train_loader, test_loader):\n",
    "    num_node_features = 5\n",
    "    num_classes = 2\n",
    "\n",
    "    # Initialize the model using the best hyperparameters\n",
    "    model = GCN(num_node_features, num_classes, hidden_channels=best_params['hidden_channels']).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), \n",
    "                                 lr=best_params['learning_rate'], \n",
    "                                 weight_decay=best_params['weight_decay'])\n",
    "\n",
    "    # Train the model on the full training data\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data)\n",
    "            loss = F.nll_loss(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred_proba = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data)\n",
    "            y_pred_proba.extend(F.softmax(out, dim=1)[:, 1].cpu().numpy())  # Get probabilities for the positive class\n",
    "            y_true.extend(data.y.cpu().numpy())\n",
    "\n",
    "    # Convert true labels and predictions to numpy arrays\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred_proba = np.array(y_pred_proba)\n",
    "\n",
    "    # Set the optimal threshold (e.g., 0.5, but you can further tune this if needed)\n",
    "    optimal_threshold = 0.5\n",
    "    y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "    # Calculate the metrics\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    auc_score = roc_auc_score(y_true, y_pred_proba)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "\n",
    "    # Print or return the evaluation results\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"AUC: {auc_score}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7797202797202797\n",
      "AUC: 0.736094674556213\n",
      "Precision: 0.8590909090909091\n",
      "Recall: 0.8552036199095022\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with the best hyperparameters\n",
    "evaluate_best_model(trial.params, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
