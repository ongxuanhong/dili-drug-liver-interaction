{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Processing compound 1/2: C[C@@H](C(=O)N[C@@H](C)C(=O)NC1[C@H]2[C@@H]1CN(C2)C3=C(C=C4C(=O)C(=CN(C4=N3)C5=C(C=C(C=C5)F)F)C(=O)O)F)N\n",
      "INFO:__main__:Processing compound 2/2: C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)N)OC3C(C(C(O3)CO)OC4C(C(C(C(O4)CN)O)O)N)O)O)N\n",
      "INFO:__main__:Final results saved to compound_info_with_toxicity.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import logging\n",
    "from rdkit import Chem\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class CompoundCrawler:\n",
    "    def __init__(self):\n",
    "        self.pubchem_base_url = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug\"\n",
    "        self.chembl_base_url = \"https://www.ebi.ac.uk/chembl/api/data\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            'User-Agent': 'Python CompoundCrawler/1.0 (responsible data mining)',\n",
    "            'Accept': 'application/json'\n",
    "        })\n",
    "\n",
    "    def get_pubchem_toxicity(self, cid: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Retrieve toxicity data from PubChem\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get bioassay data related to toxicity\n",
    "            url = f\"{self.pubchem_base_url}/compound/cid/{cid}/assaysummary/JSON\"\n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            tox_data = {\n",
    "                'LD50': [],\n",
    "                'LC50': [],\n",
    "                'EC50': [],\n",
    "                'IC50': [],\n",
    "                'toxicity_studies': []\n",
    "            }\n",
    "            \n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                if 'AssaySummaries' in data:\n",
    "                    for assay in data['AssaySummaries']:\n",
    "                        if any(term in assay.get('Name', '').lower() for term in ['toxic', 'ld50', 'lc50', 'ec50', 'ic50']):\n",
    "                            organism = assay.get('OrganismName', '')\n",
    "                            name = assay.get('Name', '')\n",
    "                            value = assay.get('Value', '')\n",
    "                            \n",
    "                            study = {\n",
    "                                'organism': organism,\n",
    "                                'assay_name': name,\n",
    "                                'value': value\n",
    "                            }\n",
    "                            \n",
    "                            if 'ld50' in name.lower():\n",
    "                                tox_data['LD50'].append(study)\n",
    "                            elif 'lc50' in name.lower():\n",
    "                                tox_data['LC50'].append(study)\n",
    "                            elif 'ec50' in name.lower():\n",
    "                                tox_data['EC50'].append(study)\n",
    "                            elif 'ic50' in name.lower():\n",
    "                                tox_data['IC50'].append(study)\n",
    "                            else:\n",
    "                                tox_data['toxicity_studies'].append(study)\n",
    "            \n",
    "            return tox_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"PubChem toxicity data error: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def get_chembl_toxicity(self, chembl_id: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Retrieve toxicity data from ChEMBL\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Get activities data\n",
    "            url = f\"{self.chembl_base_url}/activity\"\n",
    "            params = {\n",
    "                'molecule_chembl_id': chembl_id,\n",
    "                'type': 'IC50,EC50,LC50,LD50,TOX'\n",
    "            }\n",
    "            \n",
    "            response = self.session.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            tox_data = {\n",
    "                'activities': []\n",
    "            }\n",
    "            \n",
    "            if response.ok:\n",
    "                data = response.json()\n",
    "                for activity in data.get('activities', []):\n",
    "                    study = {\n",
    "                        'assay_type': activity.get('standard_type', ''),\n",
    "                        'organism': activity.get('assay_organism', ''),\n",
    "                        'target_name': activity.get('target_pref_name', ''),\n",
    "                        'value': activity.get('standard_value', ''),\n",
    "                        'units': activity.get('standard_units', ''),\n",
    "                        'activity_comment': activity.get('activity_comment', '')\n",
    "                    }\n",
    "                    tox_data['activities'].append(study)\n",
    "            \n",
    "            return tox_data\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ChEMBL toxicity data error: {e}\")\n",
    "            return {}\n",
    "\n",
    "    def get_pubchem_info(self, smiles: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Retrieve compound information from PubChem using SMILES\n",
    "        \"\"\"\n",
    "        try:\n",
    "            encoded_smiles = requests.utils.quote(smiles)\n",
    "            url = f\"{self.pubchem_base_url}/compound/smiles/{encoded_smiles}/property/IUPACName,MolecularFormula,ExactMass,CanonicalSMILES,Title/JSON\"\n",
    "            \n",
    "            response = self.session.get(url)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            if 'PropertyTable' in data and 'Properties' in data['PropertyTable']:\n",
    "                properties = data['PropertyTable']['Properties'][0]\n",
    "                \n",
    "                # Get CID for toxicity data\n",
    "                cid = properties.get('CID')\n",
    "                if cid:\n",
    "                    # Get toxicity data\n",
    "                    tox_data = self.get_pubchem_toxicity(cid)\n",
    "                    properties['toxicity_data'] = tox_data\n",
    "                    \n",
    "                    # Get description\n",
    "                    try:\n",
    "                        desc_url = f\"{self.pubchem_base_url}/compound/cid/{cid}/description/JSON\"\n",
    "                        desc_response = self.session.get(desc_url)\n",
    "                        if desc_response.ok:\n",
    "                            desc_data = desc_response.json()\n",
    "                            if 'InformationList' in desc_data and 'Information' in desc_data['InformationList']:\n",
    "                                properties['Description'] = desc_data['InformationList']['Information'][0].get('Description', '')\n",
    "                    except Exception as e:\n",
    "                        logger.warning(f\"Could not fetch description: {e}\")\n",
    "                        properties['Description'] = ''\n",
    "                \n",
    "                return properties\n",
    "            \n",
    "            return {'error': 'No PubChem data found'}\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"PubChem API error: {e}\")\n",
    "            return {'error': str(e)}\n",
    "        \n",
    "        finally:\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    def get_chembl_info(self, smiles: str) -> Dict:\n",
    "        \"\"\"\n",
    "        Retrieve compound information from ChEMBL using SMILES\n",
    "        \"\"\"\n",
    "        try:\n",
    "            url = f\"{self.chembl_base_url}/molecule\"\n",
    "            params = {\n",
    "                'molecule_structures__canonical_smiles__exact': smiles\n",
    "            }\n",
    "            \n",
    "            response = self.session.get(url, params=params)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            if not data.get('molecules'):\n",
    "                params = {\n",
    "                    'molecule_structures__canonical_smiles__flexmatch': smiles\n",
    "                }\n",
    "                response = self.session.get(url, params=params)\n",
    "                response.raise_for_status()\n",
    "                data = response.json()\n",
    "            \n",
    "            if not data.get('molecules'):\n",
    "                return {'error': 'No ChEMBL data found'}\n",
    "                \n",
    "            molecule = data['molecules'][0]\n",
    "            \n",
    "            result = {\n",
    "                'chembl_id': molecule.get('molecule_chembl_id'),\n",
    "                'pref_name': molecule.get('pref_name'),\n",
    "                'molecule_type': molecule.get('molecule_type'),\n",
    "                'max_phase': molecule.get('max_phase'),\n",
    "                'molecular_formula': molecule.get('molecule_properties', {}).get('full_molformula'),\n",
    "                'molecular_weight': molecule.get('molecule_properties', {}).get('full_mwt'),\n",
    "            }\n",
    "            \n",
    "            # Get toxicity data\n",
    "            if result['chembl_id']:\n",
    "                tox_data = self.get_chembl_toxicity(result['chembl_id'])\n",
    "                result['toxicity_data'] = tox_data\n",
    "            \n",
    "            # Get mechanism data\n",
    "            try:\n",
    "                if result['chembl_id']:\n",
    "                    activity_url = f\"{self.chembl_base_url}/mechanism\"\n",
    "                    params = {'molecule_chembl_id': result['chembl_id']}\n",
    "                    activity_response = self.session.get(activity_url, params=params)\n",
    "                    if activity_response.ok:\n",
    "                        activity_data = activity_response.json()\n",
    "                        if activity_data.get('mechanisms'):\n",
    "                            result['mechanism_of_action'] = activity_data['mechanisms'][0].get('mechanism_of_action')\n",
    "                            result['target_name'] = activity_data['mechanisms'][0].get('target_name')\n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Could not fetch mechanism data: {e}\")\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            logger.error(f\"ChEMBL API error: {e}\")\n",
    "            return {'error': str(e)}\n",
    "        \n",
    "        finally:\n",
    "            time.sleep(0.3)\n",
    "\n",
    "    def validate_smiles(self, smiles: str) -> bool:\n",
    "        \"\"\"\n",
    "        Validate SMILES string using RDKit\n",
    "        \"\"\"\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(smiles)\n",
    "            return mol is not None\n",
    "        except Exception as e:\n",
    "            logger.error(f\"SMILES validation error: {e}\")\n",
    "            return False\n",
    "\n",
    "def format_toxicity_data(tox_data: Dict) -> Dict:\n",
    "    \"\"\"\n",
    "    Format toxicity data for CSV output\n",
    "    \"\"\"\n",
    "    formatted = {}\n",
    "    \n",
    "    # Format PubChem toxicity data\n",
    "    if 'LD50' in tox_data:\n",
    "        formatted['LD50_studies'] = len(tox_data['LD50'])\n",
    "        for i, study in enumerate(tox_data['LD50'][:3]):  # Take first 3 studies\n",
    "            formatted[f'LD50_study_{i+1}'] = f\"{study['organism']}: {study['value']}\"\n",
    "    \n",
    "    if 'LC50' in tox_data:\n",
    "        formatted['LC50_studies'] = len(tox_data['LC50'])\n",
    "        for i, study in enumerate(tox_data['LC50'][:3]):\n",
    "            formatted[f'LC50_study_{i+1}'] = f\"{study['organism']}: {study['value']}\"\n",
    "    \n",
    "    if 'toxicity_studies' in tox_data:\n",
    "        formatted['other_tox_studies'] = len(tox_data['toxicity_studies'])\n",
    "        for i, study in enumerate(tox_data['toxicity_studies'][:3]):\n",
    "            formatted[f'tox_study_{i+1}'] = f\"{study['organism']}: {study['assay_name']}\"\n",
    "    \n",
    "    return formatted\n",
    "\n",
    "def process_smiles_list(smiles_list: List[str], output_file: str = 'compound_info.csv'):\n",
    "    \"\"\"\n",
    "    Process a list of SMILES strings and save results to CSV\n",
    "    \"\"\"\n",
    "    crawler = CompoundCrawler()\n",
    "    results = []\n",
    "    \n",
    "    total = len(smiles_list)\n",
    "    for idx, smiles in enumerate(smiles_list, 1):\n",
    "        logger.info(f\"Processing compound {idx}/{total}: {smiles}\")\n",
    "        \n",
    "        if not crawler.validate_smiles(smiles):\n",
    "            logger.warning(f\"Invalid SMILES: {smiles}\")\n",
    "            continue\n",
    "        \n",
    "        pubchem_data = crawler.get_pubchem_info(smiles)\n",
    "        chembl_data = crawler.get_chembl_info(smiles)\n",
    "        \n",
    "        # Format toxicity data\n",
    "        pubchem_tox = format_toxicity_data(pubchem_data.get('toxicity_data', {}))\n",
    "        chembl_tox = {}\n",
    "        if 'toxicity_data' in chembl_data and 'activities' in chembl_data['toxicity_data']:\n",
    "            for i, activity in enumerate(chembl_data['toxicity_data']['activities'][:5]):\n",
    "                chembl_tox[f'chembl_tox_{i+1}'] = (\n",
    "                    f\"{activity['assay_type']} - {activity['organism']}: \"\n",
    "                    f\"{activity['value']} {activity['units']}\"\n",
    "                )\n",
    "        \n",
    "        result = {\n",
    "            'SMILES': smiles,\n",
    "            'PubChem_IUPAC_Name': pubchem_data.get('IUPACName', ''),\n",
    "            'PubChem_Formula': pubchem_data.get('MolecularFormula', ''),\n",
    "            'PubChem_Mass': pubchem_data.get('ExactMass', ''),\n",
    "            'PubChem_Title': pubchem_data.get('Title', ''),\n",
    "            'PubChem_Description': pubchem_data.get('Description', ''),\n",
    "            'ChEMBL_ID': chembl_data.get('chembl_id', ''),\n",
    "            'ChEMBL_Name': chembl_data.get('pref_name', ''),\n",
    "            'ChEMBL_Formula': chembl_data.get('molecular_formula', ''),\n",
    "            'ChEMBL_Weight': chembl_data.get('molecular_weight', ''),\n",
    "            'ChEMBL_Type': chembl_data.get('molecule_type', ''),\n",
    "            'ChEMBL_Phase': chembl_data.get('max_phase', ''),\n",
    "            'ChEMBL_Mechanism': chembl_data.get('mechanism_of_action', ''),\n",
    "            'ChEMBL_Target': chembl_data.get('target_name', ''),\n",
    "            **pubchem_tox,  # Add PubChem toxicity data\n",
    "            **chembl_tox    # Add ChEMBL toxicity data\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        \n",
    "        # Save intermediate results every 10 compounds\n",
    "        if idx % 10 == 0:\n",
    "            pd.DataFrame(results).to_csv(output_file, index=False)\n",
    "            logger.info(f\"Intermediate results saved to {output_file}\")\n",
    "    \n",
    "    # Final save\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(output_file, index=False)\n",
    "    logger.info(f\"Final results saved to {output_file}\")\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    smiles_list = [\n",
    "        # \"CC(=O)OC1=CC=CC=C1C(=O)O\",  # Aspirin\n",
    "        # \"CN1C=NC2=C1C(=O)N(C(=O)N2C)C\"  # Caffeine\n",
    "        \"C[C@@H](C(=O)N[C@@H](C)C(=O)NC1[C@H]2[C@@H]1CN(C2)C3=C(C=C4C(=O)C(=CN(C4=N3)C5=C(C=C(C=C5)F)F)C(=O)O)F)N\",\n",
    "        \"C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)N)OC3C(C(C(O3)CO)OC4C(C(C(C(O4)CN)O)O)N)O)O)N\"\n",
    "    ]\n",
    "    \n",
    "    df = process_smiles_list(smiles_list, 'compound_info_with_toxicity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>PubChem_IUPAC_Name</th>\n",
       "      <th>PubChem_Formula</th>\n",
       "      <th>PubChem_Mass</th>\n",
       "      <th>PubChem_Title</th>\n",
       "      <th>PubChem_Description</th>\n",
       "      <th>ChEMBL_ID</th>\n",
       "      <th>ChEMBL_Name</th>\n",
       "      <th>ChEMBL_Formula</th>\n",
       "      <th>ChEMBL_Weight</th>\n",
       "      <th>ChEMBL_Type</th>\n",
       "      <th>ChEMBL_Phase</th>\n",
       "      <th>ChEMBL_Mechanism</th>\n",
       "      <th>ChEMBL_Target</th>\n",
       "      <th>LD50_studies</th>\n",
       "      <th>LC50_studies</th>\n",
       "      <th>other_tox_studies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C[C@@H](C(=O)N[C@@H](C)C(=O)NC1[C@H]2[C@@H]1CN...</td>\n",
       "      <td>7-[(1S,5R)-6-[[(2S)-2-[[(2S)-2-aminopropanoyl]...</td>\n",
       "      <td>C26H25F3N6O5</td>\n",
       "      <td>558.18385241</td>\n",
       "      <td>Alatrofloxacin</td>\n",
       "      <td></td>\n",
       "      <td>CHEMBL1200498</td>\n",
       "      <td>ALATROFLOXACIN MESYLATE</td>\n",
       "      <td>C27H29F3N6O8S</td>\n",
       "      <td>654.62</td>\n",
       "      <td>Small molecule</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Topoisomerase IV inhibitor</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)N)OC3C(C(C(...</td>\n",
       "      <td>5-amino-2-(aminomethyl)-6-[4,6-diamino-2-[4-[3...</td>\n",
       "      <td>C23H46N6O13</td>\n",
       "      <td>614.31228554</td>\n",
       "      <td>4,6-Diamino-2-{[3-o-(2,6-diamino-2,6-dideoxyhe...</td>\n",
       "      <td></td>\n",
       "      <td>CHEMBL266347</td>\n",
       "      <td>None</td>\n",
       "      <td>C23H46N6O13</td>\n",
       "      <td>614.65</td>\n",
       "      <td>Small molecule</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SMILES  \\\n",
       "0  C[C@@H](C(=O)N[C@@H](C)C(=O)NC1[C@H]2[C@@H]1CN...   \n",
       "1  C1C(C(C(C(C1N)OC2C(C(C(C(O2)CN)O)O)N)OC3C(C(C(...   \n",
       "\n",
       "                                  PubChem_IUPAC_Name PubChem_Formula  \\\n",
       "0  7-[(1S,5R)-6-[[(2S)-2-[[(2S)-2-aminopropanoyl]...    C26H25F3N6O5   \n",
       "1  5-amino-2-(aminomethyl)-6-[4,6-diamino-2-[4-[3...     C23H46N6O13   \n",
       "\n",
       "   PubChem_Mass                                      PubChem_Title  \\\n",
       "0  558.18385241                                     Alatrofloxacin   \n",
       "1  614.31228554  4,6-Diamino-2-{[3-o-(2,6-diamino-2,6-dideoxyhe...   \n",
       "\n",
       "  PubChem_Description      ChEMBL_ID              ChEMBL_Name ChEMBL_Formula  \\\n",
       "0                      CHEMBL1200498  ALATROFLOXACIN MESYLATE  C27H29F3N6O8S   \n",
       "1                       CHEMBL266347                     None    C23H46N6O13   \n",
       "\n",
       "  ChEMBL_Weight     ChEMBL_Type ChEMBL_Phase            ChEMBL_Mechanism  \\\n",
       "0        654.62  Small molecule          4.0  Topoisomerase IV inhibitor   \n",
       "1        614.65  Small molecule         None                               \n",
       "\n",
       "  ChEMBL_Target  LD50_studies  LC50_studies  other_tox_studies  \n",
       "0          None             0             0                  0  \n",
       "1                           0             0                  0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Smiles</th>\n",
       "      <th>Liver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S=C=Nc1c2c(ccc1)cccc2</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c1(c(cc(cc1[N+](=O)[O-])[N+](=O)[O-])[N+](=O)[...</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c1(c(cc(cc1)[N+](=O)[O-])[N+](=O)[O-])O</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O(CCO)CC</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oc1cc2c(cc1)cccc2</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>N1C(=NN=N1)c1ccccc1c1ccc(cc1)CN([C@H](C(=O)O)C...</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>n1cc(c(c(c1C)O)CO)CO</td>\n",
       "      <td>NonHepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1238</th>\n",
       "      <td>O1[C@H](C(=C(C1=O)O)O)[C@@H](CO)O</td>\n",
       "      <td>NonHepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1239</th>\n",
       "      <td>N(c1ccccc1)C(=O)CCCCCCC(=O)NO</td>\n",
       "      <td>NonHepatotoxicity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>N1([C@H]2C[C@H](N=N#N)[C@H](O2)CO)C(=O)NC(=O)C...</td>\n",
       "      <td>Hepatotoxicity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1241 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Smiles              Liver\n",
       "0                                 S=C=Nc1c2c(ccc1)cccc2     Hepatotoxicity\n",
       "1     c1(c(cc(cc1[N+](=O)[O-])[N+](=O)[O-])[N+](=O)[...     Hepatotoxicity\n",
       "2               c1(c(cc(cc1)[N+](=O)[O-])[N+](=O)[O-])O     Hepatotoxicity\n",
       "3                                              O(CCO)CC     Hepatotoxicity\n",
       "4                                     Oc1cc2c(cc1)cccc2     Hepatotoxicity\n",
       "...                                                 ...                ...\n",
       "1236  N1C(=NN=N1)c1ccccc1c1ccc(cc1)CN([C@H](C(=O)O)C...     Hepatotoxicity\n",
       "1237                               n1cc(c(c(c1C)O)CO)CO  NonHepatotoxicity\n",
       "1238                  O1[C@H](C(=C(C1=O)O)O)[C@@H](CO)O  NonHepatotoxicity\n",
       "1239                      N(c1ccccc1)C(=O)CCCCCCC(=O)NO  NonHepatotoxicity\n",
       "1240  N1([C@H]2C[C@H](N=N#N)[C@H](O2)CO)C(=O)NC(=O)C...     Hepatotoxicity\n",
       "\n",
       "[1241 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_train = pd.read_csv(\"data_smiles/Training_Group.csv\")\n",
    "pd_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "smiles_list = pd_train[\"Smiles\"].tolist()\n",
    "pd_train_metadata = process_smiles_list(smiles_list, 'train_compound_info_with_toxicity.csv')\n",
    "print(pd_train_metadata.shape)\n",
    "pd_train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "from typing import List, Dict, Tuple\n",
    "import logging\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class ToxicityEmbedding:\n",
    "    def __init__(self, api_key: str):\n",
    "        \"\"\"\n",
    "        Initialize the embedding creator with OpenAI API key\n",
    "        \"\"\"\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "        self.model = \"text-embedding-ada-002\"\n",
    "        \n",
    "    def create_compound_text(self, row: pd.Series) -> str:\n",
    "        \"\"\"\n",
    "        Create a text representation of compound information\n",
    "        \"\"\"\n",
    "        text_parts = []\n",
    "        \n",
    "        # Basic information\n",
    "        if row.get('PubChem_IUPAC_Name'):\n",
    "            text_parts.append(f\"IUPAC Name: {row['PubChem_IUPAC_Name']}\")\n",
    "        if row.get('PubChem_Description'):\n",
    "            text_parts.append(f\"Description: {row['PubChem_Description']}\")\n",
    "        if row.get('ChEMBL_Mechanism'):\n",
    "            text_parts.append(f\"Mechanism: {row['ChEMBL_Mechanism']}\")\n",
    "        if row.get('ChEMBL_Target'):\n",
    "            text_parts.append(f\"Target: {row['ChEMBL_Target']}\")\n",
    "            \n",
    "        # Toxicity information\n",
    "        tox_parts = []\n",
    "        # Add LD50 studies\n",
    "        for col in row.index:\n",
    "            if 'LD50_study' in col and pd.notna(row[col]):\n",
    "                tox_parts.append(f\"LD50: {row[col]}\")\n",
    "            elif 'LC50_study' in col and pd.notna(row[col]):\n",
    "                tox_parts.append(f\"LC50: {row[col]}\")\n",
    "            elif 'tox_study' in col and pd.notna(row[col]):\n",
    "                tox_parts.append(f\"Toxicity: {row[col]}\")\n",
    "            elif 'chembl_tox' in col and pd.notna(row[col]):\n",
    "                tox_parts.append(f\"ChEMBL toxicity: {row[col]}\")\n",
    "        \n",
    "        if tox_parts:\n",
    "            text_parts.append(\"Toxicity Data: \" + \"; \".join(tox_parts))\n",
    "        \n",
    "        return \" \".join(text_parts)\n",
    "    \n",
    "    def get_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Get embedding from OpenAI API\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = self.client.embeddings.create(\n",
    "                model=self.model,\n",
    "                input=text\n",
    "            )\n",
    "            return response.data[0].embedding\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting embedding: {e}\")\n",
    "            raise\n",
    "\n",
    "    def process_compounds(self, \n",
    "                         data_path: str, \n",
    "                         labels_path: str,\n",
    "                         output_path: str = 'compound_embeddings.pkl') -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Process compounds and create embeddings\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        df = pd.read_csv(data_path)\n",
    "        labels_df = pd.read_csv(labels_path)\n",
    "        \n",
    "        # Merge with labels\n",
    "        df = df.merge(labels_df, on='SMILES', how='inner')\n",
    "        \n",
    "        embeddings = []\n",
    "        texts = []\n",
    "        labels = []\n",
    "        \n",
    "        # Process each compound\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Processing compounds\"):\n",
    "            try:\n",
    "                # Create text representation\n",
    "                text = self.create_compound_text(row)\n",
    "                texts.append(text)\n",
    "                \n",
    "                # Get embedding\n",
    "                embedding = self.get_embedding(text)\n",
    "                embeddings.append(embedding)\n",
    "                \n",
    "                # Store label\n",
    "                labels.append(row['label'])\n",
    "                \n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing compound {idx}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Convert to numpy arrays\n",
    "        X = np.array(embeddings)\n",
    "        y = np.array(labels)\n",
    "        \n",
    "        # Save the processed data\n",
    "        with open(output_path, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'embeddings': X,\n",
    "                'labels': y,\n",
    "                'texts': texts\n",
    "            }, f)\n",
    "        \n",
    "        return X, y\n",
    "\n",
    "def train_classifier(X: np.ndarray, \n",
    "                    y: np.ndarray, \n",
    "                    model_type: str = 'lgb',\n",
    "                    test_size: float = 0.2,\n",
    "                    random_state: int = 42):\n",
    "    \"\"\"\n",
    "    Train a classifier on the embeddings\n",
    "    \"\"\"\n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_state, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Train model\n",
    "    if model_type == 'lgb':\n",
    "        import lightgbm as lgb\n",
    "        model = lgb.LGBMClassifier(random_state=random_state)\n",
    "    elif model_type == 'xgb':\n",
    "        import xgboost as xgb\n",
    "        model = xgb.XGBClassifier(random_state=random_state)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model type: {model_type}\")\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    # Save model and scaler\n",
    "    with open(f'toxicity_{model_type}_model.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'model': model,\n",
    "            'scaler': scaler\n",
    "        }, f)\n",
    "    \n",
    "    return model, scaler\n",
    "\n",
    "def predict_new_compounds(model_path: str,\n",
    "                        embedder: ToxicityEmbedding,\n",
    "                        new_data_path: str):\n",
    "    \"\"\"\n",
    "    Predict toxicity for new compounds\n",
    "    \"\"\"\n",
    "    # Load model and scaler\n",
    "    with open(model_path, 'rb') as f:\n",
    "        model_dict = pickle.load(f)\n",
    "    model = model_dict['model']\n",
    "    scaler = model_dict['scaler']\n",
    "    \n",
    "    # Load new data\n",
    "    df = pd.read_csv(new_data_path)\n",
    "    \n",
    "    predictions = []\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Predicting\"):\n",
    "        try:\n",
    "            # Create text and embedding\n",
    "            text = embedder.create_compound_text(row)\n",
    "            embedding = embedder.get_embedding(text)\n",
    "            \n",
    "            # Scale and predict\n",
    "            X = scaler.transform([embedding])\n",
    "            pred = model.predict(X)[0]\n",
    "            prob = model.predict_proba(X)[0]\n",
    "            \n",
    "            predictions.append({\n",
    "                'SMILES': row['SMILES'],\n",
    "                'prediction': int(pred),\n",
    "                'probability': float(prob[1])\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error predicting compound {idx}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Save predictions\n",
    "    pred_df = pd.DataFrame(predictions)\n",
    "    pred_df.to_csv('predictions.csv', index=False)\n",
    "    return pred_df\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize with your OpenAI API key\n",
    "    OPENAI_API_KEY = \"\"\n",
    "    \n",
    "    # Create embedder\n",
    "    embedder = ToxicityEmbedding(OPENAI_API_KEY)\n",
    "    \n",
    "    # Process compounds\n",
    "    X, y = embedder.process_compounds(\n",
    "        data_path='compound_info_with_toxicity.csv',\n",
    "        labels_path='compound_labels.csv'  # CSV with SMILES and label columns\n",
    "    )\n",
    "    \n",
    "    # Train classifier\n",
    "    model, scaler = train_classifier(X, y, model_type='lgb')\n",
    "    \n",
    "    # Example of predicting new compounds\n",
    "    predictions = predict_new_compounds(\n",
    "        model_path='toxicity_lgb_model.pkl',\n",
    "        embedder=embedder,\n",
    "        new_data_path='new_compounds.csv'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
