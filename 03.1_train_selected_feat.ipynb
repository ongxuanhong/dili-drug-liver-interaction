{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    AdaBoostClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    BaggingClassifier,\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_train = pd.read_csv(\"data/training_class.CSV\")\n",
    "pd_train[\"label\"] = pd_train[\"Class\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_test = pd.read_csv(\"data/testing_class.CSV\")\n",
    "pd_test[\"label\"] = pd_test[\"Class\"].apply(lambda x: 1 if x == \"Hepatotoxicity\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_sets = {\n",
    "    20: [\"FP890\", \"FP277\", \"FP937\", \"FP130\", \"FP823\", \"FP932\"],\n",
    "    50: [\n",
    "        \"FP349\",\n",
    "        \"FP890\",\n",
    "        \"FP277\",\n",
    "        \"FP937\",\n",
    "        \"KRFP298\",\n",
    "        \"FP1007\",\n",
    "        \"EStateFP33\",\n",
    "        \"FP130\",\n",
    "        \"KRFP297\",\n",
    "        \"FP802\",\n",
    "        \"FP1006\",\n",
    "        \"FP823\",\n",
    "        \"FP289\",\n",
    "        \"FP932\",\n",
    "        \"KRFPC3884\",\n",
    "    ],\n",
    "    80: [\n",
    "        \"FP168\",\n",
    "        \"KRFP297\",\n",
    "        \"FP1006\",\n",
    "        \"FP802\",\n",
    "        \"FP823\",\n",
    "        \"KRFPC4757\",\n",
    "        \"FP890\",\n",
    "        \"FP349\",\n",
    "        \"KRFP298\",\n",
    "        \"FP289\",\n",
    "        \"FP277\",\n",
    "        \"FP937\",\n",
    "        \"FP1007\",\n",
    "        \"EStateFP33\",\n",
    "        \"FP932\",\n",
    "        \"FP598\",\n",
    "        \"KRFPC3389\",\n",
    "        \"FP130\",\n",
    "        \"KRFPC3884\",\n",
    "    ],\n",
    "    100: [\n",
    "        \"FP168\",\n",
    "        \"KRFP297\",\n",
    "        \"FP1006\",\n",
    "        \"FP802\",\n",
    "        \"FP823\",\n",
    "        \"KRFPC4757\",\n",
    "        \"FP890\",\n",
    "        \"FP349\",\n",
    "        \"KRFP298\",\n",
    "        \"FP289\",\n",
    "        \"FP277\",\n",
    "        \"FP937\",\n",
    "        \"KRFP4757\",\n",
    "        \"FP1007\",\n",
    "        \"EStateFP33\",\n",
    "        \"FP187\",\n",
    "        \"FP932\",\n",
    "        \"FP355\",\n",
    "        \"FP598\",\n",
    "        \"KRFPC3389\",\n",
    "        \"FP316\",\n",
    "        \"FP130\",\n",
    "        \"KRFPC3884\",\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RidgeClassifier\": RidgeClassifier(),\n",
    "    \"SGDClassifier\": SGDClassifier(),\n",
    "    \"RandomForest\": RandomForestClassifier(),\n",
    "    \"GradientBoosting\": GradientBoostingClassifier(),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"ExtraTrees\": ExtraTreesClassifier(),\n",
    "    \"BaggingClassifier\": BaggingClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"LinearSVC\": LinearSVC(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"DecisionTree\": DecisionTreeClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(),\n",
    "    \"LightGBM\": LGBMClassifier(),\n",
    "    \"CatBoost\": CatBoostClassifier(verbose=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_k_features(pd_input_train, pd_input_test, selected_features):\n",
    "    # train val split with sklearn\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        pd_input_train[selected_features],\n",
    "        pd_input_train[\"label\"],\n",
    "        test_size=0.2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    X_test = pd_input_test[selected_features]\n",
    "    y_test = pd_input_test[\"label\"]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\predator\\anaconda3\\envs\\dili\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\predator\\anaconda3\\envs\\dili\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 540, number of negative: 452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000486 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 58\n",
      "[LightGBM] [Info] Number of data points in the train set: 992, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544355 -> initscore=0.177887\n",
      "[LightGBM] [Info] Start training from score 0.177887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\predator\\anaconda3\\envs\\dili\\lib\\site-packages\\sklearn\\svm\\_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n",
      "c:\\Users\\predator\\anaconda3\\envs\\dili\\lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 540, number of negative: 452\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000619 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 66\n",
      "[LightGBM] [Info] Number of data points in the train set: 992, number of used features: 23\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.544355 -> initscore=0.177887\n",
      "[LightGBM] [Info] Start training from score 0.177887\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# Prepare logging results\n",
    "results = []\n",
    "\n",
    "# Loop over each feature set and model\n",
    "for k in feature_sets:\n",
    "    X_train_k, y_train, X_val_k, y_val, X_test_k, y_test = select_top_k_features(\n",
    "        pd_train, pd_test, feature_sets[k]\n",
    "    )\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        # Train model\n",
    "        model.fit(X_train_k, y_train)\n",
    "\n",
    "        # Predictions\n",
    "        train_pred = model.predict(X_train_k)\n",
    "        val_pred = model.predict(X_val_k)\n",
    "        test_pred = model.predict(X_test_k)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        train_acc = accuracy_score(y_train, train_pred)\n",
    "        val_acc = accuracy_score(y_val, val_pred)\n",
    "        test_acc = accuracy_score(y_test, test_pred)\n",
    "\n",
    "        # Calculate AUC (check if probability is available)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            train_prob = model.predict_proba(X_train_k)[:, 1]\n",
    "            val_prob = model.predict_proba(X_val_k)[:, 1]\n",
    "            test_prob = model.predict_proba(X_test_k)[:, 1]\n",
    "\n",
    "            train_auc = roc_auc_score(y_train, train_prob)\n",
    "            val_auc = roc_auc_score(y_val, val_prob)\n",
    "            test_auc = roc_auc_score(y_test, test_prob)\n",
    "        else:\n",
    "            train_auc, val_auc, test_auc = None, None, None\n",
    "\n",
    "        # Log the results\n",
    "        results.append(\n",
    "            {\n",
    "                \"top_K\": k,\n",
    "                \"model\": model_name,\n",
    "                \"train_auc\": train_auc,\n",
    "                \"val_auc\": val_auc,\n",
    "                \"test_auc\": test_auc,\n",
    "                \"train_accuracy\": train_acc,\n",
    "                \"val_accuracy\": val_acc,\n",
    "                \"test_accuracy\": test_acc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Save the best model (you can modify the criterion for \"best\" as needed)\n",
    "        if val_auc is not None and val_auc == max(\n",
    "            [result[\"val_auc\"] for result in results if result[\"val_auc\"] is not None]\n",
    "        ):\n",
    "            best_model_path = f\"models/best_model_k{k}_{model_name}.pkl\"\n",
    "            joblib.dump(model, best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_K</th>\n",
       "      <th>model</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>100</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.912361</td>\n",
       "      <td>0.701676</td>\n",
       "      <td>0.859659</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.630522</td>\n",
       "      <td>0.779720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>80</td>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.880449</td>\n",
       "      <td>0.703787</td>\n",
       "      <td>0.858580</td>\n",
       "      <td>0.773185</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.779720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>100</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.958934</td>\n",
       "      <td>0.668294</td>\n",
       "      <td>0.852628</td>\n",
       "      <td>0.889113</td>\n",
       "      <td>0.622490</td>\n",
       "      <td>0.776224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>100</td>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.970952</td>\n",
       "      <td>0.659883</td>\n",
       "      <td>0.851619</td>\n",
       "      <td>0.905242</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.776224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>80</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.921649</td>\n",
       "      <td>0.692176</td>\n",
       "      <td>0.849460</td>\n",
       "      <td>0.828629</td>\n",
       "      <td>0.606426</td>\n",
       "      <td>0.758741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>80</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654234</td>\n",
       "      <td>0.622490</td>\n",
       "      <td>0.702797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>80</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671371</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.706294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>100</td>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.622490</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>100</td>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.633065</td>\n",
       "      <td>0.578313</td>\n",
       "      <td>0.660839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>100</td>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.654234</td>\n",
       "      <td>0.618474</td>\n",
       "      <td>0.723776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    top_K            model  train_auc   val_auc  test_auc  train_accuracy  \\\n",
       "63    100         CatBoost   0.912361  0.701676  0.859659        0.822581   \n",
       "47     80         CatBoost   0.880449  0.703787  0.858580        0.773185   \n",
       "61    100          XGBoost   0.958934  0.668294  0.852628        0.889113   \n",
       "51    100     RandomForest   0.970952  0.659883  0.851619        0.905242   \n",
       "45     80          XGBoost   0.921649  0.692176  0.849460        0.828629   \n",
       "..    ...              ...        ...       ...       ...             ...   \n",
       "34     80    SGDClassifier        NaN       NaN       NaN        0.654234   \n",
       "41     80        LinearSVC        NaN       NaN       NaN        0.671371   \n",
       "49    100  RidgeClassifier        NaN       NaN       NaN        0.661290   \n",
       "50    100    SGDClassifier        NaN       NaN       NaN        0.633065   \n",
       "57    100        LinearSVC        NaN       NaN       NaN        0.654234   \n",
       "\n",
       "    val_accuracy  test_accuracy  \n",
       "63      0.630522       0.779720  \n",
       "47      0.666667       0.779720  \n",
       "61      0.622490       0.776224  \n",
       "51      0.602410       0.776224  \n",
       "45      0.606426       0.758741  \n",
       "..           ...            ...  \n",
       "34      0.622490       0.702797  \n",
       "41      0.626506       0.706294  \n",
       "49      0.622490       0.730769  \n",
       "50      0.578313       0.660839  \n",
       "57      0.618474       0.723776  \n",
       "\n",
       "[64 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Export the results as a CSV report\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"models/model_performance_report.csv\", index=False)\n",
    "\n",
    "# Display the report\n",
    "df_results.sort_values(by=\"test_auc\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dili",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
